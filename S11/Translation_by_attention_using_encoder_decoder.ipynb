{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Translation_by_attention_using_encoder_decoder.ipynb","provenance":[{"file_id":"https://github.com/bastings/annotated_encoder_decoder/blob/master/annotated_encoder_decoder.ipynb","timestamp":1604163151980}],"collapsed_sections":["16aP7FaLYKyo","ChLdMs4tYKyo","v2Ayc0fbYKys","PpYFfRUVYKyx","Gf35OBCNYKyy","FWMb3VB9YKyz"],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"gZf0Ouyy_eit","executionInfo":{"status":"ok","timestamp":1605531398817,"user_tz":-330,"elapsed":1188,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"89047d5a-2072-4598-a3b0-308107f03cb5","colab":{"base_uri":"https://localhost:8080/"}},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T7p6cthQ_dtC","executionInfo":{"status":"ok","timestamp":1605531496025,"user_tz":-330,"elapsed":95846,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"af24d340-6157-4c6e-d163-952eeaf0e2a6","colab":{"base_uri":"https://localhost:8080/"}},"source":["# torch downgrade for deployment of face recog\n","!pip install torch==1.5.0 torchvision==0.6.0 -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.5.0\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torch-1.5.0%2Bcu92-cp36-cp36m-linux_x86_64.whl (603.7MB)\n","\u001b[K     |████████████████████████████████| 603.7MB 30kB/s \n","\u001b[?25hCollecting torchvision==0.6.0\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.6.0%2Bcu92-cp36-cp36m-linux_x86_64.whl (6.5MB)\n","\u001b[K     |████████████████████████████████| 6.5MB 28.1MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0) (1.18.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.0) (7.0.0)\n","Installing collected packages: torch, torchvision\n","  Found existing installation: torch 1.7.0+cu101\n","    Uninstalling torch-1.7.0+cu101:\n","      Successfully uninstalled torch-1.7.0+cu101\n","  Found existing installation: torchvision 0.8.1+cu101\n","    Uninstalling torchvision-0.8.1+cu101:\n","      Successfully uninstalled torchvision-0.8.1+cu101\n","Successfully installed torch-1.5.0+cu92 torchvision-0.6.0+cu92\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oXbW8E_BYKx-"},"source":["# The Annotated Encoder-Decoder with Attention\n","\n","Recently, Alexander Rush wrote a blog post called [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html), describing the Transformer model from the paper [Attention is All You Need](https://arxiv.org/abs/1706.03762). This post can be seen as a **prequel** to that: *we will implement an Encoder-Decoder with Attention* using (Gated) Recurrent Neural Networks, very closely following the original attention-based neural machine translation paper [\"Neural Machine Translation by Jointly Learning to Align and Translate\"](https://arxiv.org/abs/1409.0473) of Bahdanau et al. (2015). \n","\n","The idea is that going through both blog posts will make you familiar with two very influential sequence-to-sequence architectures. If you have any comments or suggestions, please let me know: [@bastings_nlp](https://twitter.com/bastings_nlp)."]},{"cell_type":"code","metadata":{"id":"zdqOycTOYKyR","executionInfo":{"status":"ok","timestamp":1605531530868,"user_tz":-330,"elapsed":1644,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"172f8b98-fac2-4277-ca78-9246c2e6552b","colab":{"base_uri":"https://localhost:8080/"}},"source":["%matplotlib inline\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math, copy, time\n","import matplotlib.pyplot as plt\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from IPython.core.debugger import set_trace\n","\n","# we will use CUDA if it is available\n","USE_CUDA = torch.cuda.is_available()\n","DEVICE=torch.device('cuda:0') # or set to 'cpu'\n","print(\"CUDA:\", USE_CUDA)\n","print(DEVICE)\n","\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["CUDA: False\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2NwdRpI4z48G"},"source":["Make_Model-->Attention-|<br>\n","Make_Model-->EncoderDecoder-->Encoder, Decoder, Generator"]},{"cell_type":"code","metadata":{"id":"_f764qjRYKyX","executionInfo":{"status":"ok","timestamp":1605531536874,"user_tz":-330,"elapsed":1404,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["class EncoderDecoder(nn.Module):\n","    \"\"\"\n","    A standard Encoder-Decoder architecture. Base for this and many \n","    other models.\n","    \"\"\"\n","    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n","        super(EncoderDecoder, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_embed = src_embed\n","        self.trg_embed = trg_embed\n","        self.generator = generator\n","        \n","    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n","        \"\"\"Take in and process masked src and target sequences.\"\"\"\n","        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n","        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n","    \n","    def encode(self, src, src_mask, src_lengths):\n","        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n","    \n","    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n","               decoder_hidden=None):\n","        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n","                            src_mask, trg_mask, hidden=decoder_hidden)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"OT4U_5LCYKyb","executionInfo":{"status":"ok","timestamp":1605531536874,"user_tz":-330,"elapsed":830,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["class Generator(nn.Module):\n","    \"\"\"Define standard linear + softmax generation step.\"\"\"\n","    def __init__(self, hidden_size, vocab_size):\n","        super(Generator, self).__init__()\n","        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n","\n","    def forward(self, x):\n","        return F.log_softmax(self.proj(x), dim=-1)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"fwdayZWuYKyf","executionInfo":{"status":"ok","timestamp":1605531537430,"user_tz":-330,"elapsed":744,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["class Encoder(nn.Module):\n","    \"\"\"Encodes a sequence of word embeddings\"\"\"\n","    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n","        super(Encoder, self).__init__()\n","        self.num_layers = num_layers\n","        self.rnn = nn.GRU(input_size, hidden_size, num_layers, \n","                          batch_first=True, bidirectional=True, dropout=dropout)\n","        \n","    def forward(self, x, mask, lengths):\n","        \"\"\"\n","        Applies a bidirectional GRU to sequence of embeddings x.\n","        The input mini-batch x needs to be sorted by length.\n","        x should have dimensions [batch, time, dim].\n","        \"\"\"\n","        packed = pack_padded_sequence(x, lengths, batch_first=True)\n","        output, final = self.rnn(packed)\n","        output, _ = pad_packed_sequence(output, batch_first=True)\n","\n","        # we need to manually concatenate the final states for both directions\n","        fwd_final = final[0:final.size(0):2]\n","        bwd_final = final[1:final.size(0):2]\n","        final = torch.cat([fwd_final, bwd_final], dim=2)  # [num_layers, batch, 2*dim]\n","\n","        return output, final"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"B5aJxHSnYKyi","executionInfo":{"status":"ok","timestamp":1605531538178,"user_tz":-330,"elapsed":900,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["class Decoder(nn.Module):\n","    \"\"\"A conditional RNN decoder with attention.\"\"\"\n","    \n","    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5,\n","                 bridge=True):\n","        super(Decoder, self).__init__()\n","        \n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.attention = attention\n","        self.dropout = dropout\n","                 \n","        self.rnn = nn.GRU(emb_size + 2*hidden_size, hidden_size, num_layers,\n","                          batch_first=True, dropout=dropout)\n","                 \n","        # to initialize from the final encoder state\n","        self.bridge = nn.Linear(2*hidden_size, hidden_size, bias=True) if bridge else None\n","\n","        self.dropout_layer = nn.Dropout(p=dropout)\n","        self.pre_output_layer = nn.Linear(hidden_size + 2*hidden_size + emb_size,\n","                                          hidden_size, bias=False)\n","        \n","    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n","        \"\"\"Perform a single decoder step (1 word)\"\"\"\n","\n","        # compute context vector using attention mechanism\n","        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n","        context, attn_probs = self.attention(\n","            query=query, proj_key=proj_key,\n","            value=encoder_hidden, mask=src_mask)\n","\n","        # update rnn hidden state\n","        rnn_input = torch.cat([prev_embed, context], dim=2)\n","        output, hidden = self.rnn(rnn_input, hidden)\n","        \n","        pre_output = torch.cat([prev_embed, output, context], dim=2)\n","        pre_output = self.dropout_layer(pre_output)\n","        pre_output = self.pre_output_layer(pre_output)\n","\n","        return output, hidden, pre_output\n","    \n","    def forward(self, trg_embed, encoder_hidden, encoder_final, \n","                src_mask, trg_mask, hidden=None, max_len=None):\n","        \"\"\"Unroll the decoder one step at a time.\"\"\"\n","                                         \n","        # the maximum number of steps to unroll the RNN\n","        if max_len is None:\n","            max_len = trg_mask.size(-1)\n","\n","        # initialize decoder hidden state\n","        if hidden is None:\n","            hidden = self.init_hidden(encoder_final)\n","        \n","        # pre-compute projected encoder hidden states\n","        # (the \"keys\" for the attention mechanism)\n","        # this is only done for efficiency\n","        proj_key = self.attention.key_layer(encoder_hidden)\n","        \n","        # here we store all intermediate hidden states and pre-output vectors\n","        decoder_states = []\n","        pre_output_vectors = []\n","        \n","        # unroll the decoder RNN for max_len steps\n","        for i in range(max_len):\n","            prev_embed = trg_embed[:, i].unsqueeze(1)\n","            output, hidden, pre_output = self.forward_step(\n","              prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n","            decoder_states.append(output)\n","            pre_output_vectors.append(pre_output)\n","\n","        decoder_states = torch.cat(decoder_states, dim=1)\n","        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n","        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n","\n","    def init_hidden(self, encoder_final):\n","        \"\"\"Returns the initial decoder state,\n","        conditioned on the final encoder state.\"\"\"\n","\n","        if encoder_final is None:\n","            return None  # start with zeros\n","\n","        return torch.tanh(self.bridge(encoder_final))            \n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"JoN3B7FlYKyl","executionInfo":{"status":"ok","timestamp":1605531538768,"user_tz":-330,"elapsed":917,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["class BahdanauAttention(nn.Module):\n","    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n","    \n","    def __init__(self, hidden_size, key_size=None, query_size=None):\n","        super(BahdanauAttention, self).__init__()\n","        \n","        # We assume a bi-directional encoder so key_size is 2*hidden_size\n","        key_size = 2 * hidden_size if key_size is None else key_size\n","        query_size = hidden_size if query_size is None else query_size\n","\n","        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n","        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n","        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n","        \n","        # to store attention scores\n","        self.alphas = None\n","        \n","    def forward(self, query=None, proj_key=None, value=None, mask=None):\n","        assert mask is not None, \"mask is required\"\n","\n","        # We first project the query (the decoder state).\n","        # The projected keys (the encoder states) were already pre-computated.\n","        query = self.query_layer(query)\n","        \n","        # Calculate scores.\n","        scores = self.energy_layer(torch.tanh(query + proj_key))\n","        scores = scores.squeeze(2).unsqueeze(1)\n","        \n","        # Mask out invalid positions.\n","        # The mask marks valid positions so we invert it using `mask & 0`.\n","        scores.data.masked_fill_(mask == 0, -float('inf'))\n","        \n","        # Turn scores to probabilities.\n","        alphas = F.softmax(scores, dim=-1)\n","        self.alphas = alphas        \n","        \n","        # The context vector is the weighted sum of the values.\n","        context = torch.bmm(alphas, value)\n","        \n","        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n","        return context, alphas"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"E5ZARlvpYKyp","executionInfo":{"status":"ok","timestamp":1605531545789,"user_tz":-330,"elapsed":1823,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["def make_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n","    \"Helper: Construct a model from hyperparameters.\"\n","\n","    attention = BahdanauAttention(hidden_size)\n","\n","    model = EncoderDecoder(\n","        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n","        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n","        nn.Embedding(src_vocab, emb_size),\n","        nn.Embedding(tgt_vocab, emb_size),\n","        Generator(hidden_size, tgt_vocab))\n","\n","    return model.cuda() if USE_CUDA else model"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"0hBWuBMJYKys","executionInfo":{"status":"ok","timestamp":1605529352092,"user_tz":-330,"elapsed":129667,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["class Batch:\n","    \"\"\"Object for holding a batch of data with mask during training.\n","    Input is a batch from a torch text iterator.\n","    \"\"\"\n","    def __init__(self, src, trg, pad_index=0):\n","        \n","        src, src_lengths = src\n","        \n","        self.src = src\n","        self.src_lengths = src_lengths\n","        self.src_mask = (src != pad_index).unsqueeze(-2)\n","        self.nseqs = src.size(0)\n","        \n","        self.trg = None\n","        self.trg_y = None\n","        self.trg_mask = None\n","        self.trg_lengths = None\n","        self.ntokens = None\n","\n","        if trg is not None:\n","            trg, trg_lengths = trg\n","            self.trg = trg[:, :-1]\n","            self.trg_lengths = trg_lengths\n","            self.trg_y = trg[:, 1:]\n","            self.trg_mask = (self.trg_y != pad_index)\n","            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n","        \n","        if USE_CUDA:\n","            self.src = self.src.cuda()\n","            self.src_mask = self.src_mask.cuda()\n","\n","            if trg is not None:\n","                self.trg = self.trg.cuda()\n","                self.trg_y = self.trg_y.cuda()\n","                self.trg_mask = self.trg_mask.cuda()\n","                "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"lZb3Y5wuYKyv","executionInfo":{"status":"ok","timestamp":1605531554807,"user_tz":-330,"elapsed":1020,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["def run_epoch(data_iter, model, loss_compute, print_every=50):\n","    \"\"\"Standard Training and Logging Function\"\"\"\n","\n","    start = time.time()\n","    total_tokens = 0\n","    total_loss = 0\n","    print_tokens = 0\n","\n","    for i, batch in enumerate(data_iter, 1):\n","        \n","        out, _, pre_output = model.forward(batch.src, batch.trg,\n","                                           batch.src_mask, batch.trg_mask,\n","                                           batch.src_lengths, batch.trg_lengths)\n","        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n","        total_loss += loss\n","        total_tokens += batch.ntokens\n","        print_tokens += batch.ntokens\n","        \n","        if model.training and i % print_every == 0:\n","            elapsed = time.time() - start\n","            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n","                    (i, loss / batch.nseqs, print_tokens / elapsed))\n","            start = time.time()\n","            print_tokens = 0\n","\n","    return math.exp(total_loss / float(total_tokens))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bp_EdEvxYKy2","executionInfo":{"status":"ok","timestamp":1605531559042,"user_tz":-330,"elapsed":1108,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["class SimpleLossCompute:\n","    \"\"\"A simple loss compute and train function.\"\"\"\n","\n","    def __init__(self, generator, criterion, opt=None):\n","        self.generator = generator\n","        self.criterion = criterion\n","        self.opt = opt\n","\n","    def __call__(self, x, y, norm):\n","        x = self.generator(x)\n","        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n","                              y.contiguous().view(-1))\n","        loss = loss / norm\n","\n","        if self.opt is not None:\n","            loss.backward()          \n","            self.opt.step()\n","            self.opt.zero_grad()\n","\n","        return loss.data.item() * norm"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"5SmtQB7_YKy5","executionInfo":{"status":"ok","timestamp":1605531560298,"user_tz":-330,"elapsed":1299,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n","    \"\"\"Greedily decode a sentence.\"\"\"\n","\n","    with torch.no_grad():\n","        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n","        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n","        trg_mask = torch.ones_like(prev_y)\n","\n","    output = []\n","    attention_scores = []\n","    hidden = None\n","\n","    for i in range(max_len):\n","        with torch.no_grad():\n","            out, hidden, pre_output = model.decode(\n","              encoder_hidden, encoder_final, src_mask,\n","              prev_y, trg_mask, hidden)\n","\n","            # we predict from the pre-output layer, which is\n","            # a combination of Decoder state, prev emb, and context\n","            prob = model.generator(pre_output[:, -1])\n","\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.data.item()\n","        output.append(next_word)\n","        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n","        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n","    \n","    output = np.array(output)\n","        \n","    # cut off everything starting from </s> \n","    # (only when eos_index provided)\n","    if eos_index is not None:\n","        first_eos = np.where(output==eos_index)[0]\n","        if len(first_eos) > 0:\n","            output = output[:first_eos[0]]      \n","    \n","    return output, np.concatenate(attention_scores, axis=1)\n","  \n","\n","def lookup_words(x, vocab=None):\n","    if vocab is not None:\n","        x = [vocab.itos[i] for i in x]\n","\n","    return [str(t) for t in x]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"gPGhQCUZYKy7","executionInfo":{"status":"ok","timestamp":1605531562721,"user_tz":-330,"elapsed":1085,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["def print_examples(example_iter, model, n=2, max_len=100, \n","                   sos_index=1, \n","                   src_eos_index=None, \n","                   trg_eos_index=None, \n","                   src_vocab=None, trg_vocab=None):\n","    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n","\n","    model.eval()\n","    count = 0\n","    print()\n","    \n","    if src_vocab is not None and trg_vocab is not None:\n","        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n","        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n","        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n","    else:\n","        src_eos_index = None\n","        trg_sos_index = 1\n","        trg_eos_index = None\n","        \n","    for i, batch in enumerate(example_iter):\n","      \n","        src = batch.src.cpu().numpy()[0, :]\n","        trg = batch.trg_y.cpu().numpy()[0, :]\n","\n","        # remove </s> (if it is there)\n","        src = src[:-1] if src[-1] == src_eos_index else src\n","        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n","      \n","        result, _ = greedy_decode(\n","          model, batch.src, batch.src_mask, batch.src_lengths,\n","          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n","        print(\"Example #%d\" % (i+1))\n","        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n","        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n","        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n","        print()\n","        \n","        count += 1\n","        if count == n:\n","            break"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZpLCo2vOYKzD"},"source":["# A Real World Example\n","\n","Now we consider a real-world example using the IWSLT German-English Translation task. \n","This task is much smaller than usual, but it illustrates the whole system. \n","\n","The cell below installs torch text and spacy. This might take a while."]},{"cell_type":"code","metadata":{"id":"ENxaqQnkYKzE","executionInfo":{"status":"ok","timestamp":1605531578991,"user_tz":-330,"elapsed":12915,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"4da24d6c-395c-4c01-941b-bd74ff9010ce","colab":{"base_uri":"https://localhost:8080/"}},"source":["#!pip install git+git://github.com/pytorch/text spacy \n","!python -m spacy download en\n","!python -m spacy download de"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.3)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.4)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","Collecting de_core_news_sm==2.2.5\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n","\u001b[K     |████████████████████████████████| 14.9MB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.4)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n","Building wheels for collected packages: de-core-news-sm\n","  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=d12344c1dbaaed11098f8238890a6bc551b52abc770e087aede14e6d3df12491\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-inrd732d/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n","Successfully built de-core-news-sm\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/de\n","You can now load the model via spacy.load('de')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OegZ-U6CYKzG"},"source":["## Data Loading\n","\n","We will load the dataset using torchtext and spacy for tokenization.\n","\n","This cell might take a while to run the first time, as it will download and tokenize the IWSLT data.\n","\n","For speed we only include short sentences, and we include a word in the vocabulary only if it occurs at least 5 times. In this case we also lowercase the data.\n","\n","If you have **issues** with torch text in the cell below (e.g. an `ascii` error), try running `export LC_ALL=\"en_US.UTF-8\"` before you start `jupyter notebook`."]},{"cell_type":"code","metadata":{"id":"zoryrgqMYKzH","executionInfo":{"status":"ok","timestamp":1605529432600,"user_tz":-330,"elapsed":210136,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"93a5a1df-991c-4dc8-c323-34510702e068","colab":{"base_uri":"https://localhost:8080/"}},"source":["# For data loading.\n","from torchtext import data, datasets\n","\n","if True:\n","    import spacy\n","    spacy_de = spacy.load('de')\n","    spacy_en = spacy.load('en')\n","\n","    def tokenize_de(text):\n","        return [tok.text for tok in spacy_de.tokenizer(text)]\n","\n","    def tokenize_en(text):\n","        return [tok.text for tok in spacy_en.tokenizer(text)]\n","\n","    UNK_TOKEN = \"<unk>\"\n","    PAD_TOKEN = \"<pad>\"    \n","    SOS_TOKEN = \"<s>\"\n","    EOS_TOKEN = \"</s>\"\n","    LOWER = True\n","    \n","    # we include lengths to provide to the RNNs\n","    SRC = data.Field(tokenize=tokenize_de, \n","                     batch_first=True, lower=LOWER, include_lengths=True,\n","                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n","    TRG = data.Field(tokenize=tokenize_en, \n","                     batch_first=True, lower=LOWER, include_lengths=True,\n","                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN)\n","\n","    MAX_LEN = 25  # NOTE: we filter out a lot of sentences for speed\n","    train_data, valid_data, test_data = datasets.IWSLT.splits(\n","        exts=('.de', '.en'), fields=(SRC, TRG), \n","        filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n","            len(vars(x)['trg']) <= MAX_LEN)\n","    MIN_FREQ = 5  # NOTE: we limit the vocabulary to frequent words for speed\n","    SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)\n","    TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n","    \n","    PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["downloading de-en.tgz\n"],"name":"stdout"},{"output_type":"stream","text":["de-en.tgz: 100%|██████████| 24.2M/24.2M [00:05<00:00, 4.73MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":[".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.en.xml\n",".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.de.xml\n",".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.en.xml\n",".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.en.xml\n",".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.en.xml\n",".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.de.xml\n",".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.en.xml\n",".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.de.xml\n",".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.de.xml\n",".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.de.xml\n",".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.de.xml\n",".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.de.xml\n",".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.en.xml\n",".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.en.xml\n",".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.de.xml\n",".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.en.xml\n",".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.de.xml\n",".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.en.xml\n",".data/iwslt/de-en/train.tags.de-en.en\n",".data/iwslt/de-en/train.tags.de-en.de\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IuZTQly2YKzJ"},"source":["### Let's look at the data\n","\n","It never hurts to look at your data and some statistics."]},{"cell_type":"code","metadata":{"id":"Bt4IxyTGYKzJ","executionInfo":{"status":"ok","timestamp":1605529432601,"user_tz":-330,"elapsed":210131,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"9a46765b-dc28-49a8-82e0-46a3d2131dc7","colab":{"base_uri":"https://localhost:8080/"}},"source":["def print_data_info(train_data, valid_data, test_data, src_field, trg_field):\n","    \"\"\" This prints some useful stuff about our data sets. \"\"\"\n","\n","    print(\"Data set sizes (number of sentence pairs):\")\n","    print('train', len(train_data))\n","    print('valid', len(valid_data))\n","    print('test', len(test_data), \"\\n\")\n","\n","    print(\"First training example:\")\n","    print(\"src:\", \" \".join(vars(train_data[0])['src']))\n","    print(\"trg:\", \" \".join(vars(train_data[0])['trg']), \"\\n\")\n","\n","    print(\"Most common words (src):\")\n","    print(\"\\n\".join([\"%10s %10d\" % x for x in src_field.vocab.freqs.most_common(10)]), \"\\n\")\n","    print(\"Most common words (trg):\")\n","    print(\"\\n\".join([\"%10s %10d\" % x for x in trg_field.vocab.freqs.most_common(10)]), \"\\n\")\n","\n","    print(\"First 10 words (src):\")\n","    print(\"\\n\".join(\n","        '%02d %s' % (i, t) for i, t in enumerate(src_field.vocab.itos[:10])), \"\\n\")\n","    print(\"First 10 words (trg):\")\n","    print(\"\\n\".join(\n","        '%02d %s' % (i, t) for i, t in enumerate(trg_field.vocab.itos[:10])), \"\\n\")\n","\n","    print(\"Number of German words (types):\", len(src_field.vocab))\n","    print(\"Number of English words (types):\", len(trg_field.vocab), \"\\n\")\n","    \n","    \n","print_data_info(train_data, valid_data, test_data, SRC, TRG)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Data set sizes (number of sentence pairs):\n","train 143115\n","valid 690\n","test 963 \n","\n","First training example:\n","src: david gallo : das ist bill lange . ich bin dave gallo .\n","trg: david gallo : this is bill lange . i 'm dave gallo . \n","\n","Most common words (src):\n","         .     138329\n","         ,     105944\n","       und      41843\n","       die      40808\n","       das      33324\n","       sie      33034\n","       ich      31150\n","       ist      31037\n","        es      27449\n","       wir      25817 \n","\n","Most common words (trg):\n","         .     137259\n","         ,      91615\n","       the      73343\n","       and      50276\n","        to      42799\n","         a      39572\n","        of      39496\n","         i      33521\n","        it      32920\n","      that      32640 \n","\n","First 10 words (src):\n","00 <unk>\n","01 <pad>\n","02 </s>\n","03 .\n","04 ,\n","05 und\n","06 die\n","07 das\n","08 sie\n","09 ich \n","\n","First 10 words (trg):\n","00 <unk>\n","01 <pad>\n","02 <s>\n","03 </s>\n","04 .\n","05 ,\n","06 the\n","07 and\n","08 to\n","09 a \n","\n","Number of German words (types): 15765\n","Number of English words (types): 13002 \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2GdfGSSOYKzL"},"source":["## Iterators\n","Batching matters a ton for speed. We will use torch text's BucketIterator here to get batches containing sentences of (almost) the same length.\n","\n","#### Note on sorting batches for RNNs in PyTorch\n","\n","For effiency reasons, PyTorch RNNs require that batches have been sorted by length, with the longest sentence in the batch first. For training, we simply sort each batch. \n","For validation, we would run into trouble if we want to compare our translations with some external file that was not sorted. Therefore we simply set the validation batch size to 1, so that we can keep it in the original order."]},{"cell_type":"code","metadata":{"id":"k_-nnReLYKzL","executionInfo":{"status":"ok","timestamp":1605529432602,"user_tz":-330,"elapsed":210123,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["train_iter = data.BucketIterator(train_data, batch_size=64, train=True, \n","                                 sort_within_batch=True, \n","                                 sort_key=lambda x: (len(x.src), len(x.trg)), repeat=False,\n","                                 device=DEVICE)\n","valid_iter = data.Iterator(valid_data, batch_size=1, train=False, sort=False, repeat=False, \n","                           device=DEVICE)\n","\n","\n","def rebatch(pad_idx, batch):\n","    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n","    return Batch(batch.src, batch.trg, pad_idx)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TjC0KGYsYKzN"},"source":["## Training the System\n","\n","Now we train the model. \n","\n","On a Titan X GPU, this runs at ~18,000 tokens per second with a batch size of 64."]},{"cell_type":"code","metadata":{"id":"3seqNRq2YKzO","executionInfo":{"status":"ok","timestamp":1605529432602,"user_tz":-330,"elapsed":210117,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["def train(model, num_epochs=10, lr=0.0003, print_every=100):\n","    \"\"\"Train a model on IWSLT\"\"\"\n","    \n","    if USE_CUDA:\n","        model.cuda()\n","\n","    # optionally add label smoothing; see the Annotated Transformer\n","    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n","    optim = torch.optim.Adam(model.parameters(), lr=lr)\n","    \n","    dev_perplexities = []\n","\n","    for epoch in range(num_epochs):\n","      \n","        print(\"Epoch\", epoch)\n","        model.train()\n","        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n","                                     model,\n","                                     SimpleLossCompute(model.generator, criterion, optim),\n","                                     print_every=print_every)\n","        \n","        model.eval()\n","        with torch.no_grad():\n","            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n","                           model, n=3, src_vocab=SRC.vocab, trg_vocab=TRG.vocab)        \n","\n","            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n","                                       model, \n","                                       SimpleLossCompute(model.generator, criterion, None))\n","            print(\"Validation perplexity: %f\" % dev_perplexity)\n","            dev_perplexities.append(dev_perplexity)\n","        \n","    return dev_perplexities\n","        "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"lA4xYAYWYKzQ","executionInfo":{"status":"ok","timestamp":1605530432175,"user_tz":-330,"elapsed":1209681,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"01b368fd-8d0f-4ed9-8926-75d005e8bee2","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = make_model(len(SRC.vocab), len(TRG.vocab),\n","                   emb_size=256, hidden_size=256,\n","                   num_layers=1, dropout=0.2)\n","dev_perplexities = train(model, print_every=100)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 0\n","Epoch Step: 100 Loss: 42.922386 Tokens per Sec: 21700.812434\n","Epoch Step: 200 Loss: 56.835735 Tokens per Sec: 23332.561178\n","Epoch Step: 300 Loss: 40.115246 Tokens per Sec: 23483.449159\n","Epoch Step: 400 Loss: 120.922829 Tokens per Sec: 22348.591187\n","Epoch Step: 500 Loss: 95.145638 Tokens per Sec: 21805.067508\n","Epoch Step: 600 Loss: 58.003689 Tokens per Sec: 22971.227450\n","Epoch Step: 700 Loss: 24.639267 Tokens per Sec: 22523.828496\n","Epoch Step: 800 Loss: 52.016762 Tokens per Sec: 23164.016319\n","Epoch Step: 900 Loss: 72.963417 Tokens per Sec: 23066.866577\n","Epoch Step: 1000 Loss: 88.452751 Tokens per Sec: 22142.266744\n","Epoch Step: 1100 Loss: 99.889015 Tokens per Sec: 22984.904388\n","Epoch Step: 1200 Loss: 90.375221 Tokens per Sec: 23638.440963\n","Epoch Step: 1300 Loss: 61.408588 Tokens per Sec: 23340.715250\n","Epoch Step: 1400 Loss: 19.801352 Tokens per Sec: 22808.471382\n","Epoch Step: 1500 Loss: 104.800674 Tokens per Sec: 23313.008203\n","Epoch Step: 1600 Loss: 57.894428 Tokens per Sec: 23323.683663\n","Epoch Step: 1700 Loss: 38.837620 Tokens per Sec: 23416.833279\n","Epoch Step: 1800 Loss: 66.247017 Tokens per Sec: 23843.014126\n","Epoch Step: 1900 Loss: 60.515179 Tokens per Sec: 21368.961288\n","Epoch Step: 2000 Loss: 51.760937 Tokens per Sec: 22404.398578\n","Epoch Step: 2100 Loss: 25.738407 Tokens per Sec: 22631.496084\n","Epoch Step: 2200 Loss: 81.291740 Tokens per Sec: 22709.319176\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  as i was born years old , i was a <unk> of the <unk> <unk> <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father have been on a little bit of the <unk> of the <unk> of the <unk> .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he was very happy , what was pretty much of the first time , it was the <unk> of the <unk> .\n","\n","Validation perplexity: 31.279206\n","Epoch 1\n","Epoch Step: 100 Loss: 29.083387 Tokens per Sec: 20519.026993\n","Epoch Step: 200 Loss: 27.983591 Tokens per Sec: 23057.127802\n","Epoch Step: 300 Loss: 53.559181 Tokens per Sec: 22448.852033\n","Epoch Step: 400 Loss: 93.775192 Tokens per Sec: 22989.947683\n","Epoch Step: 500 Loss: 71.127327 Tokens per Sec: 22303.036319\n","Epoch Step: 600 Loss: 39.952877 Tokens per Sec: 22811.793306\n","Epoch Step: 700 Loss: 55.370228 Tokens per Sec: 22529.546420\n","Epoch Step: 800 Loss: 81.621376 Tokens per Sec: 23473.769723\n","Epoch Step: 900 Loss: 50.740002 Tokens per Sec: 23046.004894\n","Epoch Step: 1000 Loss: 65.205948 Tokens per Sec: 23727.986177\n","Epoch Step: 1100 Loss: 60.520760 Tokens per Sec: 22750.946032\n","Epoch Step: 1200 Loss: 42.315346 Tokens per Sec: 22844.375671\n","Epoch Step: 1300 Loss: 32.509064 Tokens per Sec: 23630.418444\n","Epoch Step: 1400 Loss: 32.765457 Tokens per Sec: 22669.008615\n","Epoch Step: 1500 Loss: 55.342548 Tokens per Sec: 21775.173839\n","Epoch Step: 1600 Loss: 14.585047 Tokens per Sec: 23736.260930\n","Epoch Step: 1700 Loss: 36.574272 Tokens per Sec: 22808.476595\n","Epoch Step: 1800 Loss: 64.870079 Tokens per Sec: 23840.772669\n","Epoch Step: 1900 Loss: 73.978996 Tokens per Sec: 22548.701309\n","Epoch Step: 2000 Loss: 33.354195 Tokens per Sec: 23725.069232\n","Epoch Step: 2100 Loss: 36.179764 Tokens per Sec: 23861.405119\n","Epoch Step: 2200 Loss: 30.470314 Tokens per Sec: 23872.991584\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was one of the <unk> of the <unk> <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father had to be on my little , and then the <unk> of the <unk> of the <unk> .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty much of the <unk> , because the <unk> is the <unk> of the <unk> .\n","\n","Validation perplexity: 19.865915\n","Epoch 2\n","Epoch Step: 100 Loss: 31.170876 Tokens per Sec: 22277.235335\n","Epoch Step: 200 Loss: 41.136932 Tokens per Sec: 23536.850777\n","Epoch Step: 300 Loss: 45.294472 Tokens per Sec: 22455.343898\n","Epoch Step: 400 Loss: 20.083405 Tokens per Sec: 22659.010538\n","Epoch Step: 500 Loss: 47.399063 Tokens per Sec: 23236.241676\n","Epoch Step: 600 Loss: 22.421511 Tokens per Sec: 23645.751189\n","Epoch Step: 700 Loss: 62.362343 Tokens per Sec: 23805.317121\n","Epoch Step: 800 Loss: 66.264702 Tokens per Sec: 23649.929418\n","Epoch Step: 900 Loss: 12.880023 Tokens per Sec: 22159.259636\n","Epoch Step: 1000 Loss: 71.586044 Tokens per Sec: 23498.579444\n","Epoch Step: 1100 Loss: 37.677769 Tokens per Sec: 23781.627809\n","Epoch Step: 1200 Loss: 40.643852 Tokens per Sec: 23440.794076\n","Epoch Step: 1300 Loss: 12.087523 Tokens per Sec: 23589.778920\n","Epoch Step: 1400 Loss: 46.993938 Tokens per Sec: 23115.599066\n","Epoch Step: 1500 Loss: 20.622225 Tokens per Sec: 23325.331603\n","Epoch Step: 1600 Loss: 19.712811 Tokens per Sec: 23432.990834\n","Epoch Step: 1700 Loss: 73.104958 Tokens per Sec: 22735.432807\n","Epoch Step: 1800 Loss: 38.637726 Tokens per Sec: 23289.707795\n","Epoch Step: 1900 Loss: 23.918690 Tokens per Sec: 23690.579480\n","Epoch Step: 2000 Loss: 21.936722 Tokens per Sec: 23041.704294\n","Epoch Step: 2100 Loss: 39.613068 Tokens per Sec: 23589.219743\n","Epoch Step: 2200 Loss: 81.105179 Tokens per Sec: 22767.901032\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was a <unk> of the <unk> <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father heard on his little , <unk> radio the <unk> of the <unk> .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw a happy , which was very surprising , and the <unk> was the <unk> .\n","\n","Validation perplexity: 15.364933\n","Epoch 3\n","Epoch Step: 100 Loss: 71.067039 Tokens per Sec: 21179.208846\n","Epoch Step: 200 Loss: 27.685188 Tokens per Sec: 22190.363346\n","Epoch Step: 300 Loss: 16.271517 Tokens per Sec: 23009.702001\n","Epoch Step: 400 Loss: 51.936699 Tokens per Sec: 23174.943835\n","Epoch Step: 500 Loss: 11.567470 Tokens per Sec: 23228.380086\n","Epoch Step: 600 Loss: 63.553947 Tokens per Sec: 23732.673780\n","Epoch Step: 700 Loss: 6.821405 Tokens per Sec: 23175.725782\n","Epoch Step: 800 Loss: 50.420074 Tokens per Sec: 22972.323046\n","Epoch Step: 900 Loss: 20.602880 Tokens per Sec: 23443.407278\n","Epoch Step: 1000 Loss: 56.557724 Tokens per Sec: 22569.596695\n","Epoch Step: 1100 Loss: 51.133675 Tokens per Sec: 23518.644814\n","Epoch Step: 1200 Loss: 58.331635 Tokens per Sec: 23568.726475\n","Epoch Step: 1300 Loss: 35.019142 Tokens per Sec: 23858.607234\n","Epoch Step: 1400 Loss: 22.624189 Tokens per Sec: 23620.115925\n","Epoch Step: 1500 Loss: 21.840952 Tokens per Sec: 23111.463702\n","Epoch Step: 1600 Loss: 2.593366 Tokens per Sec: 23664.319108\n","Epoch Step: 1700 Loss: 23.030191 Tokens per Sec: 23258.523882\n","Epoch Step: 1800 Loss: 75.522476 Tokens per Sec: 23147.750493\n","Epoch Step: 1900 Loss: 70.030907 Tokens per Sec: 23114.298140\n","Epoch Step: 2000 Loss: 25.450748 Tokens per Sec: 23507.142827\n","Epoch Step: 2100 Loss: 66.641594 Tokens per Sec: 23998.820386\n","Epoch Step: 2200 Loss: 66.328346 Tokens per Sec: 22849.039321\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was born by the <unk> of the <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father heard on his little , radio radio radio the <unk> of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty much , because the <unk> <unk> the <unk> .\n","\n","Validation perplexity: 13.749074\n","Epoch 4\n","Epoch Step: 100 Loss: 44.170185 Tokens per Sec: 21897.190432\n","Epoch Step: 200 Loss: 4.076081 Tokens per Sec: 23682.370905\n","Epoch Step: 300 Loss: 35.035229 Tokens per Sec: 23799.224889\n","Epoch Step: 400 Loss: 29.727461 Tokens per Sec: 22634.817985\n","Epoch Step: 500 Loss: 24.442816 Tokens per Sec: 23984.234382\n","Epoch Step: 600 Loss: 31.783417 Tokens per Sec: 23192.211849\n","Epoch Step: 700 Loss: 45.781403 Tokens per Sec: 23567.705914\n","Epoch Step: 800 Loss: 35.900414 Tokens per Sec: 23673.251352\n","Epoch Step: 900 Loss: 33.745026 Tokens per Sec: 23198.936924\n","Epoch Step: 1000 Loss: 61.919563 Tokens per Sec: 23104.701770\n","Epoch Step: 1100 Loss: 38.104713 Tokens per Sec: 23288.829119\n","Epoch Step: 1200 Loss: 29.119919 Tokens per Sec: 21344.373400\n","Epoch Step: 1300 Loss: 52.361378 Tokens per Sec: 23255.055791\n","Epoch Step: 1400 Loss: 50.254814 Tokens per Sec: 23470.149981\n","Epoch Step: 1500 Loss: 57.055435 Tokens per Sec: 23218.343416\n","Epoch Step: 1600 Loss: 17.495956 Tokens per Sec: 23002.697082\n","Epoch Step: 1700 Loss: 53.860023 Tokens per Sec: 23881.539119\n","Epoch Step: 1800 Loss: 58.428215 Tokens per Sec: 23427.367671\n","Epoch Step: 1900 Loss: 44.307278 Tokens per Sec: 23579.072696\n","Epoch Step: 2000 Loss: 63.120857 Tokens per Sec: 22256.359375\n","Epoch Step: 2100 Loss: 22.881422 Tokens per Sec: 23570.378912\n","Epoch Step: 2200 Loss: 29.715666 Tokens per Sec: 23379.621790\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was a <unk> of <unk> <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father heard up on his little , radio radio shack of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was very unusual , because the news was the <unk> .\n","\n","Validation perplexity: 12.561337\n","Epoch 5\n","Epoch Step: 100 Loss: 54.629990 Tokens per Sec: 22126.794671\n","Epoch Step: 200 Loss: 57.252121 Tokens per Sec: 22047.804009\n","Epoch Step: 300 Loss: 47.745033 Tokens per Sec: 22833.531163\n","Epoch Step: 400 Loss: 31.019630 Tokens per Sec: 22477.323007\n","Epoch Step: 500 Loss: 30.796024 Tokens per Sec: 21658.842155\n","Epoch Step: 600 Loss: 10.267915 Tokens per Sec: 22883.730460\n","Epoch Step: 700 Loss: 19.648201 Tokens per Sec: 23626.187272\n","Epoch Step: 800 Loss: 40.778252 Tokens per Sec: 23639.740546\n","Epoch Step: 900 Loss: 36.964077 Tokens per Sec: 23581.109343\n","Epoch Step: 1000 Loss: 56.266968 Tokens per Sec: 22411.651314\n","Epoch Step: 1100 Loss: 12.780766 Tokens per Sec: 23474.856548\n","Epoch Step: 1200 Loss: 7.871560 Tokens per Sec: 23589.728435\n","Epoch Step: 1300 Loss: 15.683430 Tokens per Sec: 23355.325070\n","Epoch Step: 1400 Loss: 44.606129 Tokens per Sec: 23341.598343\n","Epoch Step: 1500 Loss: 24.883827 Tokens per Sec: 23493.115762\n","Epoch Step: 1600 Loss: 42.441772 Tokens per Sec: 22535.705883\n","Epoch Step: 1700 Loss: 58.810593 Tokens per Sec: 23491.845915\n","Epoch Step: 1800 Loss: 7.577053 Tokens per Sec: 22875.287139\n","Epoch Step: 1900 Loss: 24.477558 Tokens per Sec: 22555.609726\n","Epoch Step: 2000 Loss: 57.730228 Tokens per Sec: 22435.528516\n","Epoch Step: 2100 Loss: 50.618217 Tokens per Sec: 22706.869634\n","Epoch Step: 2200 Loss: 46.345905 Tokens per Sec: 22190.069707\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was a <unk> of <unk> <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my dad listened on his little , radio radio shack .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty surprising by the time , because the news was the most popular <unk> .\n","\n","Validation perplexity: 12.167314\n","Epoch 6\n","Epoch Step: 100 Loss: 31.277174 Tokens per Sec: 20999.538692\n","Epoch Step: 200 Loss: 40.718964 Tokens per Sec: 22657.681717\n","Epoch Step: 300 Loss: 11.162194 Tokens per Sec: 23199.530487\n","Epoch Step: 400 Loss: 53.741913 Tokens per Sec: 22246.426807\n","Epoch Step: 500 Loss: 35.175426 Tokens per Sec: 21998.196235\n","Epoch Step: 600 Loss: 40.028683 Tokens per Sec: 21683.539256\n","Epoch Step: 700 Loss: 9.367615 Tokens per Sec: 23177.876289\n","Epoch Step: 800 Loss: 21.695126 Tokens per Sec: 23160.760153\n","Epoch Step: 900 Loss: 26.793007 Tokens per Sec: 22264.961483\n","Epoch Step: 1000 Loss: 18.844391 Tokens per Sec: 22498.908382\n","Epoch Step: 1100 Loss: 55.602749 Tokens per Sec: 22112.266753\n","Epoch Step: 1200 Loss: 47.442123 Tokens per Sec: 22485.202694\n","Epoch Step: 1300 Loss: 5.330050 Tokens per Sec: 23870.992458\n","Epoch Step: 1400 Loss: 24.585609 Tokens per Sec: 23663.421385\n","Epoch Step: 1500 Loss: 31.589479 Tokens per Sec: 23152.727109\n","Epoch Step: 1600 Loss: 14.181542 Tokens per Sec: 23498.674120\n","Epoch Step: 1700 Loss: 21.760115 Tokens per Sec: 23562.784081\n","Epoch Step: 1800 Loss: 48.869068 Tokens per Sec: 23240.118324\n","Epoch Step: 1900 Loss: 51.328705 Tokens per Sec: 23758.801558\n","Epoch Step: 2000 Loss: 25.772350 Tokens per Sec: 23202.887391\n","Epoch Step: 2100 Loss: 47.629715 Tokens per Sec: 22534.926801\n","Epoch Step: 2200 Loss: 55.661373 Tokens per Sec: 23906.756286\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was a <unk> of <unk> , <unk> <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father listened on his little , radio radio shack .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty unusual by the time , because the u.s. public <unk> .\n","\n","Validation perplexity: 11.805327\n","Epoch 7\n","Epoch Step: 100 Loss: 30.998808 Tokens per Sec: 21803.173239\n","Epoch Step: 200 Loss: 23.849222 Tokens per Sec: 23392.105414\n","Epoch Step: 300 Loss: 11.940358 Tokens per Sec: 22492.314690\n","Epoch Step: 400 Loss: 16.144060 Tokens per Sec: 23607.383800\n","Epoch Step: 500 Loss: 17.197828 Tokens per Sec: 22586.698385\n","Epoch Step: 600 Loss: 34.528572 Tokens per Sec: 23219.392921\n","Epoch Step: 700 Loss: 5.205935 Tokens per Sec: 22732.119525\n","Epoch Step: 800 Loss: 10.444951 Tokens per Sec: 23589.057634\n","Epoch Step: 900 Loss: 38.046421 Tokens per Sec: 23606.378442\n","Epoch Step: 1000 Loss: 44.874596 Tokens per Sec: 23299.238890\n","Epoch Step: 1100 Loss: 52.823437 Tokens per Sec: 22454.338117\n","Epoch Step: 1200 Loss: 37.353680 Tokens per Sec: 22901.396074\n","Epoch Step: 1300 Loss: 31.282055 Tokens per Sec: 22839.771022\n","Epoch Step: 1400 Loss: 17.508184 Tokens per Sec: 22295.025683\n","Epoch Step: 1500 Loss: 35.503754 Tokens per Sec: 23282.962250\n","Epoch Step: 1600 Loss: 50.268631 Tokens per Sec: 23160.866230\n","Epoch Step: 1700 Loss: 17.354277 Tokens per Sec: 22561.655729\n","Epoch Step: 1800 Loss: 25.360466 Tokens per Sec: 22577.654770\n","Epoch Step: 1900 Loss: 18.324360 Tokens per Sec: 23106.176979\n","Epoch Step: 2000 Loss: 39.623798 Tokens per Sec: 22564.195680\n","Epoch Step: 2100 Loss: 48.798759 Tokens per Sec: 21580.894082\n","Epoch Step: 2200 Loss: 5.786829 Tokens per Sec: 22852.616369\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was a <unk> of <unk> <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father heard on his little , radio radio shack to the bbc of bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty staggering , which was pretty much known as the news .\n","\n","Validation perplexity: 11.838390\n","Epoch 8\n","Epoch Step: 100 Loss: 21.855614 Tokens per Sec: 20470.730356\n","Epoch Step: 200 Loss: 43.464161 Tokens per Sec: 22083.199424\n","Epoch Step: 300 Loss: 35.517181 Tokens per Sec: 23048.724719\n","Epoch Step: 400 Loss: 28.850973 Tokens per Sec: 22895.994585\n","Epoch Step: 500 Loss: 30.587856 Tokens per Sec: 23165.745283\n","Epoch Step: 600 Loss: 43.290409 Tokens per Sec: 22748.582798\n","Epoch Step: 700 Loss: 29.721315 Tokens per Sec: 23570.822751\n","Epoch Step: 800 Loss: 36.035690 Tokens per Sec: 23011.559080\n","Epoch Step: 900 Loss: 19.969603 Tokens per Sec: 23080.469678\n","Epoch Step: 1000 Loss: 31.660713 Tokens per Sec: 23284.169700\n","Epoch Step: 1100 Loss: 25.838209 Tokens per Sec: 23077.915642\n","Epoch Step: 1200 Loss: 45.181446 Tokens per Sec: 23160.141906\n","Epoch Step: 1300 Loss: 41.851871 Tokens per Sec: 23475.647218\n","Epoch Step: 1400 Loss: 52.131599 Tokens per Sec: 23006.124864\n","Epoch Step: 1500 Loss: 53.949657 Tokens per Sec: 23067.253843\n","Epoch Step: 1600 Loss: 16.254473 Tokens per Sec: 23169.233755\n","Epoch Step: 1700 Loss: 18.368324 Tokens per Sec: 23311.219673\n","Epoch Step: 1800 Loss: 37.023891 Tokens per Sec: 23173.332712\n","Epoch Step: 1900 Loss: 27.849115 Tokens per Sec: 23007.134913\n","Epoch Step: 2000 Loss: 49.699062 Tokens per Sec: 21969.170293\n","Epoch Step: 2100 Loss: 38.924946 Tokens per Sec: 22916.926302\n","Epoch Step: 2200 Loss: 50.434631 Tokens per Sec: 23424.484012\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was <unk> by the <unk> of joy .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father heard on his little , radio shack , the radio waves of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty much when he was the most precious <unk> .\n","\n","Validation perplexity: 12.006527\n","Epoch 9\n","Epoch Step: 100 Loss: 45.862774 Tokens per Sec: 21017.311370\n","Epoch Step: 200 Loss: 43.333744 Tokens per Sec: 23433.473094\n","Epoch Step: 300 Loss: 36.430725 Tokens per Sec: 22776.670340\n","Epoch Step: 400 Loss: 48.296436 Tokens per Sec: 21647.313251\n","Epoch Step: 500 Loss: 44.443966 Tokens per Sec: 23575.942055\n","Epoch Step: 600 Loss: 24.323711 Tokens per Sec: 22660.359232\n","Epoch Step: 700 Loss: 32.761780 Tokens per Sec: 23188.602651\n","Epoch Step: 800 Loss: 12.891387 Tokens per Sec: 22462.503432\n","Epoch Step: 900 Loss: 26.159744 Tokens per Sec: 23600.398949\n","Epoch Step: 1000 Loss: 47.280788 Tokens per Sec: 22921.349559\n","Epoch Step: 1100 Loss: 13.073572 Tokens per Sec: 22663.942293\n","Epoch Step: 1200 Loss: 29.386488 Tokens per Sec: 23327.752520\n","Epoch Step: 1300 Loss: 35.807690 Tokens per Sec: 22494.244419\n","Epoch Step: 1400 Loss: 15.641349 Tokens per Sec: 22095.791880\n","Epoch Step: 1500 Loss: 18.530872 Tokens per Sec: 22014.916227\n","Epoch Step: 1600 Loss: 17.811075 Tokens per Sec: 22541.194994\n","Epoch Step: 1700 Loss: 33.020191 Tokens per Sec: 22827.798931\n","Epoch Step: 1800 Loss: 46.898685 Tokens per Sec: 22316.682717\n","Epoch Step: 1900 Loss: 44.128353 Tokens per Sec: 23613.120819\n","Epoch Step: 2000 Loss: 43.609493 Tokens per Sec: 22824.201923\n","Epoch Step: 2100 Loss: 34.673019 Tokens per Sec: 22575.050176\n","Epoch Step: 2200 Loss: 40.285694 Tokens per Sec: 23701.799234\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was <unk> by <unk> by the <unk> of the <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father heard on his little , <unk> radio , the radio waves of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he looked very happy , which was pretty staggering , which was the most popular <unk> .\n","\n","Validation perplexity: 12.011447\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O_FgUGTV597_"},"source":["## Save the Model"]},{"cell_type":"code","metadata":{"id":"f57YgrgU6Bfy","executionInfo":{"status":"ok","timestamp":1605530432177,"user_tz":-330,"elapsed":1209673,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["torch.save(model.state_dict(), 'translation-encoder-decoder-de-en.pt')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1H5gITG6Fxx","executionInfo":{"status":"ok","timestamp":1605530432177,"user_tz":-330,"elapsed":1209667,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"eac496b4-bcc0-4ff4-a8e4-4b1bca8bc027","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = make_model(len(SRC.vocab), len(TRG.vocab),\n","                   emb_size=256, hidden_size=256,\n","                   num_layers=1, dropout=0.2)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FxwL8CER6Jpn","executionInfo":{"status":"ok","timestamp":1605530432178,"user_tz":-330,"elapsed":1209663,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["model = model.to(DEVICE)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBcAt_sr6MW5","executionInfo":{"status":"ok","timestamp":1605531028900,"user_tz":-330,"elapsed":1109,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"661ffa80-7a98-462a-9584-626ad2cf0965","colab":{"base_uri":"https://localhost:8080/"}},"source":["state_dict = torch.load('translation-encoder-decoder-de-en.pt')\n","model.load_state_dict(state_dict)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"eOcaQlgN6TAP"},"source":["## Save MetaData"]},{"cell_type":"code","metadata":{"id":"5jJNOnc86Wrr","executionInfo":{"status":"ok","timestamp":1605531166169,"user_tz":-330,"elapsed":1205,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["def save_meta(meta, path):\n","    import dill\n","    output = open(path, 'wb')\n","    dill.dump(meta, output)\n","    output.close()"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"GH1VaVTB6ajj","executionInfo":{"status":"ok","timestamp":1605531606503,"user_tz":-330,"elapsed":1058,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["def load_meta(path):\n","    import dill\n","    inp = open(path, \"rb\")\n","    meta = dill.load(inp)\n","    inp.close()\n","    \n","    return meta"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"CZLbp0yW6eSR","executionInfo":{"status":"ok","timestamp":1605531167583,"user_tz":-330,"elapsed":1733,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["save_meta({\n","    \"UNK_TOKEN\": \"<unk>\",\n","    \"PAD_TOKEN\": \"<pad>\",    \n","    \"SOS_TOKEN\": \"<s>\",\n","    \"EOS_TOKEN\": \"</s>\",\n","    \"TRG.vocab.itos\": TRG.vocab.itos,\n","    \"TRG.vocab.stoi\": TRG.vocab.stoi,\n","    \"SRC.vocab.itos\": SRC.vocab.itos,\n","    \"SRC.vocab.stoi\": SRC.vocab.stoi,\n","}, 'de-to-en-meta.dill.pkl')"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_iIh2cs6lQy","executionInfo":{"status":"ok","timestamp":1605531612582,"user_tz":-330,"elapsed":1061,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["meta = load_meta('/content/de-to-en-meta.dill.pkl')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"rNB32JyJ6rlr","executionInfo":{"status":"ok","timestamp":1605531615585,"user_tz":-330,"elapsed":1042,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"fc675acf-a2ac-4aa4-873a-0b9cae40a46f","colab":{"base_uri":"https://localhost:8080/"}},"source":["meta.keys()"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['UNK_TOKEN', 'PAD_TOKEN', 'SOS_TOKEN', 'EOS_TOKEN', 'TRG.vocab.itos', 'TRG.vocab.stoi', 'SRC.vocab.itos', 'SRC.vocab.stoi'])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"-jlhQoNo6yJR","executionInfo":{"status":"ok","timestamp":1605531617950,"user_tz":-330,"elapsed":892,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"a3deb9cd-90bf-45b8-f72d-1cf2ee9892d3","colab":{"base_uri":"https://localhost:8080/"}},"source":["[type(meta[item]) for item in meta.keys()]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[str,\n"," str,\n"," str,\n"," str,\n"," list,\n"," collections.defaultdict,\n"," list,\n"," collections.defaultdict]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"6hRDE8J27DGr"},"source":["## Checking Run"]},{"cell_type":"code","metadata":{"id":"2xJWuOA47L1j","executionInfo":{"status":"ok","timestamp":1605531630809,"user_tz":-330,"elapsed":1196,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"504ecb40-d7aa-4565-f9bc-fe3403f88afc","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = make_model(len(meta['SRC.vocab.itos']), len(meta['TRG.vocab.itos']),\n","                   emb_size=256, hidden_size=256,\n","                   num_layers=1, dropout=0.2)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lVq1ga7X7MwS","executionInfo":{"status":"ok","timestamp":1605532072098,"user_tz":-330,"elapsed":1079,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["model_state = torch.load('/content/translation-encoder-decoder-de-en.pt', map_location='cpu')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"DWpxJCMP7P4N","executionInfo":{"status":"ok","timestamp":1605532073837,"user_tz":-330,"elapsed":658,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"501e4a32-ecb6-48aa-d0dc-e12288f457ad","colab":{"base_uri":"https://localhost:8080/"}},"source":["model.load_state_dict(model_state)"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"nEGa420T7VXb","executionInfo":{"status":"ok","timestamp":1605532078637,"user_tz":-330,"elapsed":1124,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"b00b6489-730f-4ec6-a348-2b387e65f459","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["ger = 'als ich 11 jahre alt war, wurde ich eines morgens von den heller freude geweckt.'\n","ger"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'als ich 11 jahre alt war, wurde ich eines morgens von den heller freude geweckt.'"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"0D9roqlQLDYl","executionInfo":{"status":"ok","timestamp":1605532191768,"user_tz":-330,"elapsed":3702,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["import spacy\n","spacy_de = spacy.load('de')\n","spacy_en = spacy.load('en')\n","\n","def tokenize_de(text):\n","    return [tok.text for tok in spacy_de.tokenizer(text)]\n","\n","def tokenize_en(text):\n","    return [tok.text for tok in spacy_en.tokenizer(text)]"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNRNQ8C77YHf","executionInfo":{"status":"ok","timestamp":1605532193258,"user_tz":-330,"elapsed":726,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"ac66d46b-b717-4f61-e9f5-42edc329fc89","colab":{"base_uri":"https://localhost:8080/"}},"source":["ger_tok = tokenize_de(ger)\n","ger_tok"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['als',\n"," 'ich',\n"," '11',\n"," 'jahre',\n"," 'alt',\n"," 'war',\n"," ',',\n"," 'wurde',\n"," 'ich',\n"," 'eines',\n"," 'morgens',\n"," 'von',\n"," 'den',\n"," 'heller',\n"," 'freude',\n"," 'geweckt',\n"," '.']"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"k5UhI_B77j7h","executionInfo":{"status":"ok","timestamp":1605532194979,"user_tz":-330,"elapsed":712,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"7c1a0335-0268-4be4-9f46-4326cf246e6b","colab":{"base_uri":"https://localhost:8080/"}},"source":["src = [meta['SRC.vocab.stoi'][x] for x in ger_tok] + [meta['SRC.vocab.stoi'][meta[\"EOS_TOKEN\"]]]\n","src"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[41,\n"," 9,\n"," 1012,\n"," 144,\n"," 464,\n"," 35,\n"," 4,\n"," 84,\n"," 9,\n"," 126,\n"," 1715,\n"," 21,\n"," 27,\n"," 11351,\n"," 1117,\n"," 8043,\n"," 3,\n"," 2]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"dRLP7b0Q7nTH","executionInfo":{"status":"ok","timestamp":1605532197763,"user_tz":-330,"elapsed":1005,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"d120934c-cbe3-4922-ebb0-bd1c30fb42e5","colab":{"base_uri":"https://localhost:8080/"}},"source":["[meta['SRC.vocab.itos'][x] for x in src]"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['als',\n"," 'ich',\n"," '11',\n"," 'jahre',\n"," 'alt',\n"," 'war',\n"," ',',\n"," 'wurde',\n"," 'ich',\n"," 'eines',\n"," 'morgens',\n"," 'von',\n"," 'den',\n"," 'heller',\n"," 'freude',\n"," 'geweckt',\n"," '.',\n"," '</s>']"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"zEwPiTUyBZ3o","executionInfo":{"status":"ok","timestamp":1605532200278,"user_tz":-330,"elapsed":1133,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"7d8cf28e-7231-4ca5-f05b-1db73e4271b4","colab":{"base_uri":"https://localhost:8080/"}},"source":["src_length = [len(src)]\n","src_length"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[18]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"6JzCupSABgcn","executionInfo":{"status":"ok","timestamp":1605532201820,"user_tz":-330,"elapsed":693,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"f92b4f01-12e4-43f7-a781-574ff1764ac6","colab":{"base_uri":"https://localhost:8080/"}},"source":["src_mask = torch.ones(src_length) > 0\n","src_mask"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"4n0atInDBjzn","executionInfo":{"status":"ok","timestamp":1605532203572,"user_tz":-330,"elapsed":1006,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"964fb3b2-7d2b-44f7-d6a4-dd108d48ce37","colab":{"base_uri":"https://localhost:8080/"}},"source":["meta['SRC.vocab.stoi'][meta['PAD_TOKEN']], meta['TRG.vocab.stoi'][meta['PAD_TOKEN']]"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 1)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"Fl11UJIoBoKl","executionInfo":{"status":"ok","timestamp":1605532205176,"user_tz":-330,"elapsed":921,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"274a51a9-c593-4ff0-e95e-6a74c675787f","colab":{"base_uri":"https://localhost:8080/"}},"source":["meta['SRC.vocab.stoi'][meta['SOS_TOKEN']], meta['TRG.vocab.stoi'][meta['SOS_TOKEN']]"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0, 2)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"VnCnrZMRBsZt","executionInfo":{"status":"ok","timestamp":1605532206701,"user_tz":-330,"elapsed":885,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"f2c9cefd-a629-405d-abca-9da6822b26a9","colab":{"base_uri":"https://localhost:8080/"}},"source":["meta['SRC.vocab.stoi'][meta['EOS_TOKEN']], meta['TRG.vocab.stoi'][meta['EOS_TOKEN']]"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 3)"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"xsvFwR6UBweL","executionInfo":{"status":"ok","timestamp":1605532208383,"user_tz":-330,"elapsed":1117,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["# src, src_masks, src_lengths\n","src = torch.LongTensor(src)\n","src_mask = (src != meta['SRC.vocab.stoi'][meta['PAD_TOKEN']]).unsqueeze(-2)\n","src_length = torch.tensor(len(src))"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"PTCnH3iOB11v","executionInfo":{"status":"ok","timestamp":1605532210226,"user_tz":-330,"elapsed":1194,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"5203534c-198a-497a-ca89-bf183247fbf1","colab":{"base_uri":"https://localhost:8080/"}},"source":["src, src_mask, src_length"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([   41,     9,  1012,   144,   464,    35,     4,    84,     9,   126,\n","          1715,    21,    27, 11351,  1117,  8043,     3,     2]),\n"," tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n","          True, True, True, True, True, True]]),\n"," tensor(18))"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"tGIGDvfiB62E","executionInfo":{"status":"ok","timestamp":1605532211993,"user_tz":-330,"elapsed":1171,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["src = src.unsqueeze(0)\n","src_mask = src_mask.unsqueeze(0)\n","src_length = src_length.unsqueeze(0)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"xIGHcyGDB-qy","executionInfo":{"status":"ok","timestamp":1605532213617,"user_tz":-330,"elapsed":1044,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"83408923-f111-4282-c8c4-dc280dd80a0c","colab":{"base_uri":"https://localhost:8080/"}},"source":["src.shape, src_mask.shape, src_length.shape"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 18]), torch.Size([1, 1, 18]), torch.Size([1]))"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"4ubsfCbyCBy2","executionInfo":{"status":"ok","timestamp":1605532325740,"user_tz":-330,"elapsed":1005,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["output,_ = greedy_decode(\n","    model, \n","    src, \n","    src_mask, \n","    src_length, \n","    max_len=100, \n","    sos_index=meta['TRG.vocab.stoi'][meta['SOS_TOKEN']], \n","    eos_index=meta['TRG.vocab.stoi'][meta['EOS_TOKEN']]\n","    )"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tnt7pKXxCGqH","executionInfo":{"status":"ok","timestamp":1605532332044,"user_tz":-330,"elapsed":1093,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"63f1b326-c518-482b-ccaa-8a7ee3b1a450","colab":{"base_uri":"https://localhost:8080/"}},"source":["output.shape"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(16,)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"nHFoidF9CJz0","executionInfo":{"status":"ok","timestamp":1605532336214,"user_tz":-330,"elapsed":1129,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"91cf41c7-b94d-48cf-e715-2c3ca288529c","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(\" \".join([meta['TRG.vocab.itos'][x] for x in output ]))"],"execution_count":45,"outputs":[{"output_type":"stream","text":["when i was 11 years old , i was <unk> by one of the <unk> .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZjqA0EpZLzut","executionInfo":{"status":"ok","timestamp":1605532707518,"user_tz":-330,"elapsed":1230,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"23b04742-039f-4065-e20b-7110d35f1bf5","colab":{"base_uri":"https://localhost:8080/"}},"source":["meta['TRG.vocab.itos']=='called'"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"ClRPi4enNDS1"},"source":[""],"execution_count":null,"outputs":[]}]}