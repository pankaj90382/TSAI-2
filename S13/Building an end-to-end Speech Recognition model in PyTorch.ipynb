{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Building an end-to-end Speech Recognition model in PyTorch","provenance":[{"file_id":"1Z-4MiFimY9JPWk93V0MwblXu2iS8Lzp0","timestamp":1606209672429},{"file_id":"1IPpwx4rX32rqHKpLz7dc8sOKspUa-YKO","timestamp":1604656236930}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ibD6bsRPl8Qu"},"source":["# Building an end-to-end Speech Recognition model in PyTorch - [AssemblyAI](https://www.assemblyai.com/)"]},{"cell_type":"markdown","metadata":{"id":"q1fXgsDQmK09"},"source":["## installing the requirements"]},{"cell_type":"code","metadata":{"id":"gwfN8o17Bdp2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606378707950,"user_tz":-330,"elapsed":4796,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"eabe17c6-52b5-4b98-f281-d41220cc577d"},"source":["!pip install torchaudio"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting torchaudio\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/23/6b54106b3de029d3f10cf8debc302491c17630357449c900d6209665b302/torchaudio-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (7.6MB)\n","\u001b[K     |████████████████████████████████| 7.6MB 12.3MB/s \n","\u001b[?25hRequirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio) (1.7.0+cu101)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio) (1.18.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio) (0.8)\n","Installing collected packages: torchaudio\n","Successfully installed torchaudio-0.7.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tSKHvy8DmOCQ"},"source":["## Setting up your data pipeline"]},{"cell_type":"code","metadata":{"id":"RVJs4Bk8FjjO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606378712083,"user_tz":-330,"elapsed":8909,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"62d22f05-c601-4e8a-a5f1-431ae8ba7d05"},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.utils.data as data\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchaudio\n","import numpy as np\n","\n","def avg_wer(wer_scores, combined_ref_len):\n","    return float(sum(wer_scores)) / float(combined_ref_len)\n","\n","\n","def _levenshtein_distance(ref, hyp):\n","    \"\"\"Levenshtein distance is a string metric for measuring the difference\n","    between two sequences. Informally, the levenshtein disctance is defined as\n","    the minimum number of single-character edits (substitutions, insertions or\n","    deletions) required to change one word into the other. We can naturally\n","    extend the edits to word level when calculate levenshtein disctance for\n","    two sentences.\n","    \"\"\"\n","    m = len(ref)\n","    n = len(hyp)\n","\n","    # special case\n","    if ref == hyp:\n","        return 0\n","    if m == 0:\n","        return n\n","    if n == 0:\n","        return m\n","\n","    if m < n:\n","        ref, hyp = hyp, ref\n","        m, n = n, m\n","\n","    # use O(min(m, n)) space\n","    distance = np.zeros((2, n + 1), dtype=np.int32)\n","\n","    # initialize distance matrix\n","    for j in range(0,n + 1):\n","        distance[0][j] = j\n","\n","    # calculate levenshtein distance\n","    for i in range(1, m + 1):\n","        prev_row_idx = (i - 1) % 2\n","        cur_row_idx = i % 2\n","        distance[cur_row_idx][0] = i\n","        for j in range(1, n + 1):\n","            if ref[i - 1] == hyp[j - 1]:\n","                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n","            else:\n","                s_num = distance[prev_row_idx][j - 1] + 1\n","                i_num = distance[cur_row_idx][j - 1] + 1\n","                d_num = distance[prev_row_idx][j] + 1\n","                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n","\n","    return distance[m % 2][n]\n","\n","\n","def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n","    \"\"\"Compute the levenshtein distance between reference sequence and\n","    hypothesis sequence in word-level.\n","    :param reference: The reference sentence.\n","    :type reference: basestring\n","    :param hypothesis: The hypothesis sentence.\n","    :type hypothesis: basestring\n","    :param ignore_case: Whether case-sensitive or not.\n","    :type ignore_case: bool\n","    :param delimiter: Delimiter of input sentences.\n","    :type delimiter: char\n","    :return: Levenshtein distance and word number of reference sentence.\n","    :rtype: list\n","    \"\"\"\n","    if ignore_case == True:\n","        reference = reference.lower()\n","        hypothesis = hypothesis.lower()\n","\n","    ref_words = reference.split(delimiter)\n","    hyp_words = hypothesis.split(delimiter)\n","\n","    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n","    return float(edit_distance), len(ref_words)\n","\n","\n","def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n","    \"\"\"Compute the levenshtein distance between reference sequence and\n","    hypothesis sequence in char-level.\n","    :param reference: The reference sentence.\n","    :type reference: basestring\n","    :param hypothesis: The hypothesis sentence.\n","    :type hypothesis: basestring\n","    :param ignore_case: Whether case-sensitive or not.\n","    :type ignore_case: bool\n","    :param remove_space: Whether remove internal space characters\n","    :type remove_space: bool\n","    :return: Levenshtein distance and length of reference sentence.\n","    :rtype: list\n","    \"\"\"\n","    if ignore_case == True:\n","        reference = reference.lower()\n","        hypothesis = hypothesis.lower()\n","\n","    join_char = ' '\n","    if remove_space == True:\n","        join_char = ''\n","\n","    reference = join_char.join(filter(None, reference.split(' ')))\n","    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n","\n","    edit_distance = _levenshtein_distance(reference, hypothesis)\n","    return float(edit_distance), len(reference)\n","\n","\n","def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n","    \"\"\"Calculate word error rate (WER). WER compares reference text and\n","    hypothesis text in word-level. WER is defined as:\n","    .. math::\n","        WER = (Sw + Dw + Iw) / Nw\n","    where\n","    .. code-block:: text\n","        Sw is the number of words subsituted,\n","        Dw is the number of words deleted,\n","        Iw is the number of words inserted,\n","        Nw is the number of words in the reference\n","    We can use levenshtein distance to calculate WER. Please draw an attention\n","    that empty items will be removed when splitting sentences by delimiter.\n","    :param reference: The reference sentence.\n","    :type reference: basestring\n","    :param hypothesis: The hypothesis sentence.\n","    :type hypothesis: basestring\n","    :param ignore_case: Whether case-sensitive or not.\n","    :type ignore_case: bool\n","    :param delimiter: Delimiter of input sentences.\n","    :type delimiter: char\n","    :return: Word error rate.\n","    :rtype: float\n","    :raises ValueError: If word number of reference is zero.\n","    \"\"\"\n","    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n","                                         delimiter)\n","\n","    if ref_len == 0:\n","        raise ValueError(\"Reference's word number should be greater than 0.\")\n","\n","    wer = float(edit_distance) / ref_len\n","    return wer\n","\n","\n","def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n","    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n","    hypothesis text in char-level. CER is defined as:\n","    .. math::\n","        CER = (Sc + Dc + Ic) / Nc\n","    where\n","    .. code-block:: text\n","        Sc is the number of characters substituted,\n","        Dc is the number of characters deleted,\n","        Ic is the number of characters inserted\n","        Nc is the number of characters in the reference\n","    We can use levenshtein distance to calculate CER. Chinese input should be\n","    encoded to unicode. Please draw an attention that the leading and tailing\n","    space characters will be truncated and multiple consecutive space\n","    characters in a sentence will be replaced by one space character.\n","    :param reference: The reference sentence.\n","    :type reference: basestring\n","    :param hypothesis: The hypothesis sentence.\n","    :type hypothesis: basestring\n","    :param ignore_case: Whether case-sensitive or not.\n","    :type ignore_case: bool\n","    :param remove_space: Whether remove internal space characters\n","    :type remove_space: bool\n","    :return: Character error rate.\n","    :rtype: float\n","    :raises ValueError: If the reference length is zero.\n","    \"\"\"\n","    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n","                                         remove_space)\n","\n","    if ref_len == 0:\n","        raise ValueError(\"Length of reference should be greater than 0.\")\n","\n","    cer = float(edit_distance) / ref_len\n","    return cer\n","\n","class TextTransform:\n","    \"\"\"Maps characters to integers and vice versa\"\"\"\n","    def __init__(self):\n","        char_map_str = \"\"\"\n","        ' 0\n","        <SPACE> 1\n","        a 2\n","        b 3\n","        c 4\n","        d 5\n","        e 6\n","        f 7\n","        g 8\n","        h 9\n","        i 10\n","        j 11\n","        k 12\n","        l 13\n","        m 14\n","        n 15\n","        o 16\n","        p 17\n","        q 18\n","        r 19\n","        s 20\n","        t 21\n","        u 22\n","        v 23\n","        w 24\n","        x 25\n","        y 26\n","        z 27\n","        \"\"\"\n","        self.char_map = {}\n","        self.index_map = {}\n","        for line in char_map_str.strip().split('\\n'):\n","            ch, index = line.split()\n","            self.char_map[ch] = int(index)\n","            self.index_map[int(index)] = ch\n","        self.index_map[1] = ' '\n","\n","    def text_to_int(self, text):\n","        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n","        int_sequence = []\n","        for c in text:\n","            if c == ' ':\n","                ch = self.char_map['<SPACE>']\n","            else:\n","                ch = self.char_map[c]\n","            int_sequence.append(ch)\n","        return int_sequence\n","\n","    def int_to_text(self, labels):\n","        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n","        string = []\n","        for i in labels:\n","            string.append(self.index_map[i])\n","        return ''.join(string).replace('<SPACE>', ' ')\n","\n","train_audio_transforms = nn.Sequential(\n","    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n","    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n","    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",")\n","\n","valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n","\n","text_transform = TextTransform()\n","\n","def data_processing(data, data_type=\"train\"):\n","    spectrograms = []\n","    labels = []\n","    input_lengths = []\n","    label_lengths = []\n","    for (waveform, _, utterance, _, _, _) in data:\n","        if data_type == 'train':\n","            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n","        elif data_type == 'valid':\n","            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n","        else:\n","            raise Exception('data_type should be train or valid')\n","        spectrograms.append(spec)\n","        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n","        labels.append(label)\n","        input_lengths.append(spec.shape[0]//2)\n","        label_lengths.append(len(label))\n","\n","    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n","    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n","\n","    return spectrograms, labels, input_lengths, label_lengths\n","\n","\n","def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n","\targ_maxes = torch.argmax(output, dim=2)\n","\tdecodes = []\n","\ttargets = []\n","\tfor i, args in enumerate(arg_maxes):\n","\t\tdecode = []\n","\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n","\t\tfor j, index in enumerate(args):\n","\t\t\tif index != blank_label:\n","\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n","\t\t\t\t\tcontinue\n","\t\t\t\tdecode.append(index.item())\n","\t\tdecodes.append(text_transform.int_to_text(decode))\n","\treturn decodes, targets\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n","  '\"sox\" backend is being deprecated. '\n","/usr/local/lib/python3.6/dist-packages/torchaudio/functional.py:318: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n","  \"At least one mel filterbank has all zero values. \"\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"4XdSlhAQnDEA"},"source":["## The Model\n","Base of of Deep Speech 2 with some personal improvements"]},{"cell_type":"code","metadata":{"id":"65H1-PCjm-FB","executionInfo":{"status":"ok","timestamp":1606378712086,"user_tz":-330,"elapsed":8906,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["class CNNLayerNorm(nn.Module):\n","    \"\"\"Layer normalization built for cnns input\"\"\"\n","    def __init__(self, n_feats):\n","        super(CNNLayerNorm, self).__init__()\n","        self.layer_norm = nn.LayerNorm(n_feats)\n","\n","    def forward(self, x):\n","        # x (batch, channel, feature, time)\n","        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n","        x = self.layer_norm(x)\n","        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n","\n","\n","class ResidualCNN(nn.Module):\n","    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n","        except with layer norm instead of batch norm\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n","        super(ResidualCNN, self).__init__()\n","\n","        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n","        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","        self.layer_norm1 = CNNLayerNorm(n_feats)\n","        self.layer_norm2 = CNNLayerNorm(n_feats)\n","\n","    def forward(self, x):\n","        residual = x  # (batch, channel, feature, time)\n","        x = self.layer_norm1(x)\n","        x = F.gelu(x)\n","        x = self.dropout1(x)\n","        x = self.cnn1(x)\n","        x = self.layer_norm2(x)\n","        x = F.gelu(x)\n","        x = self.dropout2(x)\n","        x = self.cnn2(x)\n","        x += residual\n","        return x # (batch, channel, feature, time)\n","\n","\n","class BidirectionalGRU(nn.Module):\n","\n","    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n","        super(BidirectionalGRU, self).__init__()\n","\n","        self.BiGRU = nn.GRU(\n","            input_size=rnn_dim, hidden_size=hidden_size,\n","            num_layers=1, batch_first=batch_first, bidirectional=True)\n","        self.layer_norm = nn.LayerNorm(rnn_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        x = self.layer_norm(x)\n","        x = F.gelu(x)\n","        x, _ = self.BiGRU(x)\n","        x = self.dropout(x)\n","        return x\n","\n","\n","class SpeechRecognitionModel(nn.Module):\n","    \n","    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n","        super(SpeechRecognitionModel, self).__init__()\n","        n_feats = n_feats//2\n","        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n","\n","        # n residual cnn layers with filter size of 32\n","        self.rescnn_layers = nn.Sequential(*[\n","            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n","            for _ in range(n_cnn_layers)\n","        ])\n","        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n","        self.birnn_layers = nn.Sequential(*[\n","            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n","                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n","            for i in range(n_rnn_layers)\n","        ])\n","        self.classifier = nn.Sequential(\n","            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(rnn_dim, n_class)\n","        )\n","\n","    def forward(self, x):\n","        x = self.cnn(x)\n","        x = self.rescnn_layers(x)\n","        sizes = x.size()\n","        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n","        x = x.transpose(1, 2) # (batch, time, feature)\n","        x = self.fully_connected(x)\n","        x = self.birnn_layers(x)\n","        x = self.classifier(x)\n","        return x\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CuguNEzKnMOn"},"source":["## The Training and Evaluating Script"]},{"cell_type":"code","metadata":{"id":"ydkqGeOwnPGY","executionInfo":{"status":"ok","timestamp":1606378712088,"user_tz":-330,"elapsed":8903,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["class IterMeter(object):\n","    \"\"\"keeps track of total iterations\"\"\"\n","    def __init__(self):\n","        self.val = 0\n","\n","    def step(self):\n","        self.val += 1\n","\n","    def get(self):\n","        return self.val\n","\n","\n","def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n","    model.train()\n","    data_len = len(train_loader.dataset)\n","    for batch_idx, _data in enumerate(train_loader):\n","        spectrograms, labels, input_lengths, label_lengths = _data \n","        spectrograms, labels = spectrograms.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(spectrograms)  # (batch, time, n_class)\n","        output = F.log_softmax(output, dim=2)\n","        output = output.transpose(0, 1) # (time, batch, n_class)\n","\n","        loss = criterion(output, labels, input_lengths, label_lengths)\n","        loss.backward()\n","\n","        optimizer.step()\n","        scheduler.step()\n","        iter_meter.step()\n","        if batch_idx % 100 == 0 or batch_idx == data_len:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(spectrograms), data_len,\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","\n","def test(model, device, test_loader, criterion, epoch, iter_meter):\n","    print('\\nevaluating...')\n","    model.eval()\n","    test_loss = 0\n","    test_cer, test_wer = [], []\n","    with torch.no_grad():\n","        for i, _data in enumerate(test_loader):\n","            spectrograms, labels, input_lengths, label_lengths = _data \n","            spectrograms, labels = spectrograms.to(device), labels.to(device)\n","\n","            output = model(spectrograms)  # (batch, time, n_class)\n","            output = F.log_softmax(output, dim=2)\n","            output = output.transpose(0, 1) # (time, batch, n_class)\n","\n","            loss = criterion(output, labels, input_lengths, label_lengths)\n","            test_loss += loss.item() / len(test_loader)\n","\n","            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n","            for j in range(len(decoded_preds)):\n","                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n","                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n","\n","\n","    avg_cer = sum(test_cer)/len(test_cer)\n","    avg_wer = sum(test_wer)/len(test_wer)\n","\n","    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HxRIb_WempDq"},"source":["## GPU runtime\n","If you are using a GPU runtime, this will let you know what GPU and how much memory is available. Adjust your batch_size depending on which GPU"]},{"cell_type":"code","metadata":{"id":"nlUSuAJwlzo8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606378712090,"user_tz":-330,"elapsed":8890,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"e762fd6f-5d4c-4966-86ee-5b936d953637"},"source":["!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Thu Nov 26 08:18:32 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hXvlWZeVpXfX"},"source":["## Train\n","this will download the data on first run and may take a while. "]},{"cell_type":"code","metadata":{"id":"XZodve8PGKfS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606405424505,"user_tz":-330,"elapsed":20782468,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}},"outputId":"3721b6ab-682e-4f2a-e75f-69175ad26915"},"source":["learning_rate = 5e-4\n","batch_size = 10\n","epochs = 10\n","train_url = \"train-clean-100\"\n","test_url = \"test-clean\"\n","\n","hparams = {\n","    \"n_cnn_layers\": 3,\n","    \"n_rnn_layers\": 5,\n","    \"rnn_dim\": 512,\n","    \"n_class\": 29,\n","    \"n_feats\": 128,\n","    \"stride\":2,\n","    \"dropout\": 0.1,\n","    \"learning_rate\": learning_rate,\n","    \"batch_size\": batch_size,\n","    \"epochs\": epochs\n","}\n","\n","use_cuda = torch.cuda.is_available()\n","torch.manual_seed(7)\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","if not os.path.isdir(\"./data\"):\n","    os.makedirs(\"./data\")\n","\n","train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n","test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = data.DataLoader(dataset=train_dataset,\n","                            batch_size=hparams['batch_size'],\n","                            shuffle=True,\n","                            collate_fn=lambda x: data_processing(x, 'train'),\n","                            **kwargs)\n","test_loader = data.DataLoader(dataset=test_dataset,\n","                            batch_size=hparams['batch_size'],\n","                            shuffle=False,\n","                            collate_fn=lambda x: data_processing(x, 'valid'),\n","                            **kwargs)\n","\n","model = SpeechRecognitionModel(\n","    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n","    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n","    ).to(device)\n","\n","print(model)\n","print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n","\n","optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n","criterion = nn.CTCLoss(blank=28).to(device)\n","scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n","                                        steps_per_epoch=int(len(train_loader)),\n","                                        epochs=hparams['epochs'],\n","                                        anneal_strategy='linear')\n","\n","iter_meter = IterMeter()\n","for epoch in range(1, epochs + 1):\n","    train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n","    test(model, device, test_loader, criterion, epoch, iter_meter)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["SpeechRecognitionModel(\n","  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (rescnn_layers): Sequential(\n","    (0): ResidualCNN(\n","      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (dropout1): Dropout(p=0.1, inplace=False)\n","      (dropout2): Dropout(p=0.1, inplace=False)\n","      (layer_norm1): CNNLayerNorm(\n","        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (layer_norm2): CNNLayerNorm(\n","        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (1): ResidualCNN(\n","      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (dropout1): Dropout(p=0.1, inplace=False)\n","      (dropout2): Dropout(p=0.1, inplace=False)\n","      (layer_norm1): CNNLayerNorm(\n","        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (layer_norm2): CNNLayerNorm(\n","        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (2): ResidualCNN(\n","      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (dropout1): Dropout(p=0.1, inplace=False)\n","      (dropout2): Dropout(p=0.1, inplace=False)\n","      (layer_norm1): CNNLayerNorm(\n","        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (layer_norm2): CNNLayerNorm(\n","        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n","  (birnn_layers): Sequential(\n","    (0): BidirectionalGRU(\n","      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n","      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (1): BidirectionalGRU(\n","      (BiGRU): GRU(1024, 512, bidirectional=True)\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (2): BidirectionalGRU(\n","      (BiGRU): GRU(1024, 512, bidirectional=True)\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (3): BidirectionalGRU(\n","      (BiGRU): GRU(1024, 512, bidirectional=True)\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (4): BidirectionalGRU(\n","      (BiGRU): GRU(1024, 512, bidirectional=True)\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=1024, out_features=512, bias=True)\n","    (1): GELU()\n","    (2): Dropout(p=0.1, inplace=False)\n","    (3): Linear(in_features=512, out_features=29, bias=True)\n","  )\n",")\n","Num Model Parameters 23705373\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 1 [0/28539 (0%)]\tLoss: 7.135164\n","Train Epoch: 1 [1000/28539 (4%)]\tLoss: 2.907269\n","Train Epoch: 1 [2000/28539 (7%)]\tLoss: 2.871370\n","Train Epoch: 1 [3000/28539 (11%)]\tLoss: 2.867666\n","Train Epoch: 1 [4000/28539 (14%)]\tLoss: 2.880453\n","Train Epoch: 1 [5000/28539 (18%)]\tLoss: 2.870227\n","Train Epoch: 1 [6000/28539 (21%)]\tLoss: 2.846277\n","Train Epoch: 1 [7000/28539 (25%)]\tLoss: 2.854157\n","Train Epoch: 1 [8000/28539 (28%)]\tLoss: 2.871848\n","Train Epoch: 1 [9000/28539 (32%)]\tLoss: 2.842756\n","Train Epoch: 1 [10000/28539 (35%)]\tLoss: 2.867663\n","Train Epoch: 1 [11000/28539 (39%)]\tLoss: 2.855093\n","Train Epoch: 1 [12000/28539 (42%)]\tLoss: 2.830522\n","Train Epoch: 1 [13000/28539 (46%)]\tLoss: 2.833481\n","Train Epoch: 1 [14000/28539 (49%)]\tLoss: 2.777253\n","Train Epoch: 1 [15000/28539 (53%)]\tLoss: 2.753206\n","Train Epoch: 1 [16000/28539 (56%)]\tLoss: 2.541107\n","Train Epoch: 1 [17000/28539 (60%)]\tLoss: 2.520226\n","Train Epoch: 1 [18000/28539 (63%)]\tLoss: 2.291565\n","Train Epoch: 1 [19000/28539 (67%)]\tLoss: 2.132872\n","Train Epoch: 1 [20000/28539 (70%)]\tLoss: 1.964451\n","Train Epoch: 1 [21000/28539 (74%)]\tLoss: 1.974793\n","Train Epoch: 1 [22000/28539 (77%)]\tLoss: 1.843573\n","Train Epoch: 1 [23000/28539 (81%)]\tLoss: 1.999583\n","Train Epoch: 1 [24000/28539 (84%)]\tLoss: 1.798214\n","Train Epoch: 1 [25000/28539 (88%)]\tLoss: 1.751154\n","Train Epoch: 1 [26000/28539 (91%)]\tLoss: 1.715759\n","Train Epoch: 1 [27000/28539 (95%)]\tLoss: 1.616973\n","Train Epoch: 1 [28000/28539 (98%)]\tLoss: 1.821505\n","\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Test set: Average loss: 1.4564, Average CER: 0.434663 Average WER: 0.9417\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 2 [0/28539 (0%)]\tLoss: 1.797063\n","Train Epoch: 2 [1000/28539 (4%)]\tLoss: 1.753189\n","Train Epoch: 2 [2000/28539 (7%)]\tLoss: 1.512712\n","Train Epoch: 2 [3000/28539 (11%)]\tLoss: 1.605343\n","Train Epoch: 2 [4000/28539 (14%)]\tLoss: 1.553710\n","Train Epoch: 2 [5000/28539 (18%)]\tLoss: 1.573267\n","Train Epoch: 2 [6000/28539 (21%)]\tLoss: 1.308695\n","Train Epoch: 2 [7000/28539 (25%)]\tLoss: 1.410526\n","Train Epoch: 2 [8000/28539 (28%)]\tLoss: 1.511794\n","Train Epoch: 2 [9000/28539 (32%)]\tLoss: 1.409000\n","Train Epoch: 2 [10000/28539 (35%)]\tLoss: 1.300855\n","Train Epoch: 2 [11000/28539 (39%)]\tLoss: 1.432331\n","Train Epoch: 2 [12000/28539 (42%)]\tLoss: 1.293200\n","Train Epoch: 2 [13000/28539 (46%)]\tLoss: 1.292668\n","Train Epoch: 2 [14000/28539 (49%)]\tLoss: 1.272024\n","Train Epoch: 2 [15000/28539 (53%)]\tLoss: 1.364683\n","Train Epoch: 2 [16000/28539 (56%)]\tLoss: 1.235338\n","Train Epoch: 2 [17000/28539 (60%)]\tLoss: 1.571774\n","Train Epoch: 2 [18000/28539 (63%)]\tLoss: 1.245528\n","Train Epoch: 2 [19000/28539 (67%)]\tLoss: 1.435709\n","Train Epoch: 2 [20000/28539 (70%)]\tLoss: 1.300178\n","Train Epoch: 2 [21000/28539 (74%)]\tLoss: 1.336175\n","Train Epoch: 2 [22000/28539 (77%)]\tLoss: 1.162574\n","Train Epoch: 2 [23000/28539 (81%)]\tLoss: 1.239096\n","Train Epoch: 2 [24000/28539 (84%)]\tLoss: 1.254779\n","Train Epoch: 2 [25000/28539 (88%)]\tLoss: 1.276136\n","Train Epoch: 2 [26000/28539 (91%)]\tLoss: 1.145738\n","Train Epoch: 2 [27000/28539 (95%)]\tLoss: 1.274670\n","Train Epoch: 2 [28000/28539 (98%)]\tLoss: 1.288237\n","\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Test set: Average loss: 1.0253, Average CER: 0.317614 Average WER: 0.7863\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 3 [0/28539 (0%)]\tLoss: 1.162685\n","Train Epoch: 3 [1000/28539 (4%)]\tLoss: 1.129675\n","Train Epoch: 3 [2000/28539 (7%)]\tLoss: 1.178760\n","Train Epoch: 3 [3000/28539 (11%)]\tLoss: 1.507751\n","Train Epoch: 3 [4000/28539 (14%)]\tLoss: 1.079893\n","Train Epoch: 3 [5000/28539 (18%)]\tLoss: 1.312800\n","Train Epoch: 3 [6000/28539 (21%)]\tLoss: 1.330964\n","Train Epoch: 3 [7000/28539 (25%)]\tLoss: 1.222336\n","Train Epoch: 3 [8000/28539 (28%)]\tLoss: 1.258644\n","Train Epoch: 3 [9000/28539 (32%)]\tLoss: 1.092902\n","Train Epoch: 3 [10000/28539 (35%)]\tLoss: 1.105976\n","Train Epoch: 3 [11000/28539 (39%)]\tLoss: 1.018903\n","Train Epoch: 3 [12000/28539 (42%)]\tLoss: 1.164968\n","Train Epoch: 3 [13000/28539 (46%)]\tLoss: 1.093200\n","Train Epoch: 3 [14000/28539 (49%)]\tLoss: 1.209281\n","Train Epoch: 3 [15000/28539 (53%)]\tLoss: 1.327647\n","Train Epoch: 3 [16000/28539 (56%)]\tLoss: 1.253286\n","Train Epoch: 3 [17000/28539 (60%)]\tLoss: 1.115595\n","Train Epoch: 3 [18000/28539 (63%)]\tLoss: 1.381941\n","Train Epoch: 3 [19000/28539 (67%)]\tLoss: 1.220115\n","Train Epoch: 3 [20000/28539 (70%)]\tLoss: 0.994151\n","Train Epoch: 3 [21000/28539 (74%)]\tLoss: 1.219449\n","Train Epoch: 3 [22000/28539 (77%)]\tLoss: 1.088710\n","Train Epoch: 3 [23000/28539 (81%)]\tLoss: 1.101945\n","Train Epoch: 3 [24000/28539 (84%)]\tLoss: 1.178286\n","Train Epoch: 3 [25000/28539 (88%)]\tLoss: 1.310155\n","Train Epoch: 3 [26000/28539 (91%)]\tLoss: 1.154382\n","Train Epoch: 3 [27000/28539 (95%)]\tLoss: 1.140363\n","Train Epoch: 3 [28000/28539 (98%)]\tLoss: 1.063907\n","\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Test set: Average loss: 0.8837, Average CER: 0.270768 Average WER: 0.7245\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 4 [0/28539 (0%)]\tLoss: 1.047072\n","Train Epoch: 4 [1000/28539 (4%)]\tLoss: 1.078069\n","Train Epoch: 4 [2000/28539 (7%)]\tLoss: 0.959594\n","Train Epoch: 4 [3000/28539 (11%)]\tLoss: 0.959866\n","Train Epoch: 4 [4000/28539 (14%)]\tLoss: 1.186820\n","Train Epoch: 4 [5000/28539 (18%)]\tLoss: 0.986068\n","Train Epoch: 4 [6000/28539 (21%)]\tLoss: 0.999129\n","Train Epoch: 4 [7000/28539 (25%)]\tLoss: 0.898429\n","Train Epoch: 4 [8000/28539 (28%)]\tLoss: 1.083018\n","Train Epoch: 4 [9000/28539 (32%)]\tLoss: 1.072919\n","Train Epoch: 4 [10000/28539 (35%)]\tLoss: 1.089268\n","Train Epoch: 4 [11000/28539 (39%)]\tLoss: 1.048468\n","Train Epoch: 4 [12000/28539 (42%)]\tLoss: 1.128556\n","Train Epoch: 4 [13000/28539 (46%)]\tLoss: 1.074161\n","Train Epoch: 4 [14000/28539 (49%)]\tLoss: 1.037729\n","Train Epoch: 4 [15000/28539 (53%)]\tLoss: 0.897661\n","Train Epoch: 4 [16000/28539 (56%)]\tLoss: 1.007742\n","Train Epoch: 4 [17000/28539 (60%)]\tLoss: 0.936540\n","Train Epoch: 4 [18000/28539 (63%)]\tLoss: 0.947968\n","Train Epoch: 4 [19000/28539 (67%)]\tLoss: 0.983004\n","Train Epoch: 4 [20000/28539 (70%)]\tLoss: 1.055173\n","Train Epoch: 4 [21000/28539 (74%)]\tLoss: 0.895628\n","Train Epoch: 4 [22000/28539 (77%)]\tLoss: 1.041196\n","Train Epoch: 4 [23000/28539 (81%)]\tLoss: 1.005814\n","Train Epoch: 4 [24000/28539 (84%)]\tLoss: 1.031652\n","Train Epoch: 4 [25000/28539 (88%)]\tLoss: 1.065166\n","Train Epoch: 4 [26000/28539 (91%)]\tLoss: 0.859629\n","Train Epoch: 4 [27000/28539 (95%)]\tLoss: 1.078098\n","Train Epoch: 4 [28000/28539 (98%)]\tLoss: 0.967636\n","\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Test set: Average loss: 0.7855, Average CER: 0.238744 Average WER: 0.6552\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 5 [0/28539 (0%)]\tLoss: 0.809964\n","Train Epoch: 5 [1000/28539 (4%)]\tLoss: 0.886706\n","Train Epoch: 5 [2000/28539 (7%)]\tLoss: 1.056996\n","Train Epoch: 5 [3000/28539 (11%)]\tLoss: 0.925537\n","Train Epoch: 5 [4000/28539 (14%)]\tLoss: 1.005396\n","Train Epoch: 5 [5000/28539 (18%)]\tLoss: 1.226554\n","Train Epoch: 5 [6000/28539 (21%)]\tLoss: 0.713901\n","Train Epoch: 5 [7000/28539 (25%)]\tLoss: 0.890570\n","Train Epoch: 5 [8000/28539 (28%)]\tLoss: 0.924418\n","Train Epoch: 5 [9000/28539 (32%)]\tLoss: 0.832107\n","Train Epoch: 5 [10000/28539 (35%)]\tLoss: 0.941164\n","Train Epoch: 5 [11000/28539 (39%)]\tLoss: 1.166611\n","Train Epoch: 5 [12000/28539 (42%)]\tLoss: 0.932021\n","Train Epoch: 5 [13000/28539 (46%)]\tLoss: 1.044557\n","Train Epoch: 5 [14000/28539 (49%)]\tLoss: 0.856590\n","Train Epoch: 5 [15000/28539 (53%)]\tLoss: 1.040720\n","Train Epoch: 5 [16000/28539 (56%)]\tLoss: 0.924650\n","Train Epoch: 5 [17000/28539 (60%)]\tLoss: 0.951140\n","Train Epoch: 5 [18000/28539 (63%)]\tLoss: 0.886346\n","Train Epoch: 5 [19000/28539 (67%)]\tLoss: 0.949387\n","Train Epoch: 5 [20000/28539 (70%)]\tLoss: 0.833432\n","Train Epoch: 5 [21000/28539 (74%)]\tLoss: 0.937598\n","Train Epoch: 5 [22000/28539 (77%)]\tLoss: 0.966091\n","Train Epoch: 5 [23000/28539 (81%)]\tLoss: 0.879128\n","Train Epoch: 5 [24000/28539 (84%)]\tLoss: 0.923874\n","Train Epoch: 5 [25000/28539 (88%)]\tLoss: 0.742355\n","Train Epoch: 5 [26000/28539 (91%)]\tLoss: 0.862041\n","Train Epoch: 5 [27000/28539 (95%)]\tLoss: 0.888241\n","Train Epoch: 5 [28000/28539 (98%)]\tLoss: 0.776083\n","\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Test set: Average loss: 0.6958, Average CER: 0.212795 Average WER: 0.6011\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 6 [0/28539 (0%)]\tLoss: 0.720254\n","Train Epoch: 6 [1000/28539 (4%)]\tLoss: 0.862347\n","Train Epoch: 6 [2000/28539 (7%)]\tLoss: 0.893428\n","Train Epoch: 6 [3000/28539 (11%)]\tLoss: 1.024072\n","Train Epoch: 6 [4000/28539 (14%)]\tLoss: 0.965571\n","Train Epoch: 6 [5000/28539 (18%)]\tLoss: 0.826779\n","Train Epoch: 6 [6000/28539 (21%)]\tLoss: 0.819390\n","Train Epoch: 6 [7000/28539 (25%)]\tLoss: 0.837130\n","Train Epoch: 6 [8000/28539 (28%)]\tLoss: 1.004098\n","Train Epoch: 6 [9000/28539 (32%)]\tLoss: 0.683089\n","Train Epoch: 6 [10000/28539 (35%)]\tLoss: 1.049018\n","Train Epoch: 6 [11000/28539 (39%)]\tLoss: 0.918859\n","Train Epoch: 6 [12000/28539 (42%)]\tLoss: 0.955716\n","Train Epoch: 6 [13000/28539 (46%)]\tLoss: 1.036511\n","Train Epoch: 6 [14000/28539 (49%)]\tLoss: 0.868258\n","Train Epoch: 6 [15000/28539 (53%)]\tLoss: 0.907983\n","Train Epoch: 6 [16000/28539 (56%)]\tLoss: 0.883205\n","Train Epoch: 6 [17000/28539 (60%)]\tLoss: 0.785447\n","Train Epoch: 6 [18000/28539 (63%)]\tLoss: 0.899719\n","Train Epoch: 6 [19000/28539 (67%)]\tLoss: 0.851121\n","Train Epoch: 6 [20000/28539 (70%)]\tLoss: 0.799924\n","Train Epoch: 6 [21000/28539 (74%)]\tLoss: 1.022629\n","Train Epoch: 6 [22000/28539 (77%)]\tLoss: 0.715544\n","Train Epoch: 6 [23000/28539 (81%)]\tLoss: 0.857459\n","Train Epoch: 6 [24000/28539 (84%)]\tLoss: 0.841173\n","Train Epoch: 6 [25000/28539 (88%)]\tLoss: 0.641430\n","Train Epoch: 6 [26000/28539 (91%)]\tLoss: 0.910972\n","Train Epoch: 6 [27000/28539 (95%)]\tLoss: 0.817336\n","Train Epoch: 6 [28000/28539 (98%)]\tLoss: 0.772397\n","\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Test set: Average loss: 0.6480, Average CER: 0.196505 Average WER: 0.5640\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 7 [0/28539 (0%)]\tLoss: 0.683799\n","Train Epoch: 7 [1000/28539 (4%)]\tLoss: 0.937962\n","Train Epoch: 7 [2000/28539 (7%)]\tLoss: 0.963863\n","Train Epoch: 7 [3000/28539 (11%)]\tLoss: 0.764113\n","Train Epoch: 7 [4000/28539 (14%)]\tLoss: 0.854394\n","Train Epoch: 7 [5000/28539 (18%)]\tLoss: 0.811235\n","Train Epoch: 7 [6000/28539 (21%)]\tLoss: 0.890342\n","Train Epoch: 7 [7000/28539 (25%)]\tLoss: 0.722600\n","Train Epoch: 7 [8000/28539 (28%)]\tLoss: 0.841771\n","Train Epoch: 7 [9000/28539 (32%)]\tLoss: 0.819206\n","Train Epoch: 7 [10000/28539 (35%)]\tLoss: 0.970066\n","Train Epoch: 7 [11000/28539 (39%)]\tLoss: 0.731961\n","Train Epoch: 7 [12000/28539 (42%)]\tLoss: 0.922850\n","Train Epoch: 7 [13000/28539 (46%)]\tLoss: 1.045769\n","Train Epoch: 7 [14000/28539 (49%)]\tLoss: 0.977083\n","Train Epoch: 7 [15000/28539 (53%)]\tLoss: 0.788865\n","Train Epoch: 7 [16000/28539 (56%)]\tLoss: 0.674906\n","Train Epoch: 7 [17000/28539 (60%)]\tLoss: 0.861943\n","Train Epoch: 7 [18000/28539 (63%)]\tLoss: 0.720615\n","Train Epoch: 7 [19000/28539 (67%)]\tLoss: 0.777763\n","Train Epoch: 7 [20000/28539 (70%)]\tLoss: 0.867530\n","Train Epoch: 7 [21000/28539 (74%)]\tLoss: 0.784993\n","Train Epoch: 7 [22000/28539 (77%)]\tLoss: 0.690545\n","Train Epoch: 7 [23000/28539 (81%)]\tLoss: 0.839009\n","Train Epoch: 7 [24000/28539 (84%)]\tLoss: 0.760575\n","Train Epoch: 7 [25000/28539 (88%)]\tLoss: 0.828121\n","Train Epoch: 7 [26000/28539 (91%)]\tLoss: 0.811693\n","Train Epoch: 7 [27000/28539 (95%)]\tLoss: 0.842806\n","Train Epoch: 7 [28000/28539 (98%)]\tLoss: 0.826563\n","\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Test set: Average loss: 0.6132, Average CER: 0.186355 Average WER: 0.5406\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 8 [0/28539 (0%)]\tLoss: 0.679045\n","Train Epoch: 8 [1000/28539 (4%)]\tLoss: 0.691602\n","Train Epoch: 8 [2000/28539 (7%)]\tLoss: 0.978365\n","Train Epoch: 8 [3000/28539 (11%)]\tLoss: 0.730681\n","Train Epoch: 8 [4000/28539 (14%)]\tLoss: 0.723052\n","Train Epoch: 8 [5000/28539 (18%)]\tLoss: 0.653844\n","Train Epoch: 8 [6000/28539 (21%)]\tLoss: 0.899476\n","Train Epoch: 8 [7000/28539 (25%)]\tLoss: 0.780697\n","Train Epoch: 8 [8000/28539 (28%)]\tLoss: 0.710351\n","Train Epoch: 8 [9000/28539 (32%)]\tLoss: 0.705313\n","Train Epoch: 8 [10000/28539 (35%)]\tLoss: 0.871681\n","Train Epoch: 8 [11000/28539 (39%)]\tLoss: 0.902212\n","Train Epoch: 8 [12000/28539 (42%)]\tLoss: 0.784064\n","Train Epoch: 8 [13000/28539 (46%)]\tLoss: 0.688393\n","Train Epoch: 8 [14000/28539 (49%)]\tLoss: 0.735173\n","Train Epoch: 8 [15000/28539 (53%)]\tLoss: 0.740419\n","Train Epoch: 8 [16000/28539 (56%)]\tLoss: 0.837003\n","Train Epoch: 8 [17000/28539 (60%)]\tLoss: 0.638819\n","Train Epoch: 8 [18000/28539 (63%)]\tLoss: 0.810619\n","Train Epoch: 8 [19000/28539 (67%)]\tLoss: 0.817183\n","Train Epoch: 8 [20000/28539 (70%)]\tLoss: 0.899441\n","Train Epoch: 8 [21000/28539 (74%)]\tLoss: 0.691645\n","Train Epoch: 8 [22000/28539 (77%)]\tLoss: 0.593715\n","Train Epoch: 8 [23000/28539 (81%)]\tLoss: 0.692754\n","Train Epoch: 8 [24000/28539 (84%)]\tLoss: 0.824752\n","Train Epoch: 8 [25000/28539 (88%)]\tLoss: 0.674482\n","Train Epoch: 8 [26000/28539 (91%)]\tLoss: 0.649892\n","Train Epoch: 8 [27000/28539 (95%)]\tLoss: 0.715959\n","Train Epoch: 8 [28000/28539 (98%)]\tLoss: 0.667162\n","\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Test set: Average loss: 0.5851, Average CER: 0.175994 Average WER: 0.5167\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 9 [0/28539 (0%)]\tLoss: 0.700319\n","Train Epoch: 9 [1000/28539 (4%)]\tLoss: 0.719772\n","Train Epoch: 9 [2000/28539 (7%)]\tLoss: 0.605339\n","Train Epoch: 9 [3000/28539 (11%)]\tLoss: 0.719385\n","Train Epoch: 9 [4000/28539 (14%)]\tLoss: 0.684694\n","Train Epoch: 9 [5000/28539 (18%)]\tLoss: 0.781191\n","Train Epoch: 9 [6000/28539 (21%)]\tLoss: 0.940090\n","Train Epoch: 9 [7000/28539 (25%)]\tLoss: 0.709771\n","Train Epoch: 9 [8000/28539 (28%)]\tLoss: 0.587472\n","Train Epoch: 9 [9000/28539 (32%)]\tLoss: 0.606193\n","Train Epoch: 9 [10000/28539 (35%)]\tLoss: 0.661487\n","Train Epoch: 9 [11000/28539 (39%)]\tLoss: 0.775205\n","Train Epoch: 9 [12000/28539 (42%)]\tLoss: 0.609422\n","Train Epoch: 9 [13000/28539 (46%)]\tLoss: 0.814804\n","Train Epoch: 9 [14000/28539 (49%)]\tLoss: 0.714932\n","Train Epoch: 9 [15000/28539 (53%)]\tLoss: 0.864783\n","Train Epoch: 9 [16000/28539 (56%)]\tLoss: 0.646436\n","Train Epoch: 9 [17000/28539 (60%)]\tLoss: 0.669182\n","Train Epoch: 9 [18000/28539 (63%)]\tLoss: 0.837237\n","Train Epoch: 9 [19000/28539 (67%)]\tLoss: 0.754964\n","Train Epoch: 9 [20000/28539 (70%)]\tLoss: 0.583708\n","Train Epoch: 9 [21000/28539 (74%)]\tLoss: 0.882842\n","Train Epoch: 9 [22000/28539 (77%)]\tLoss: 0.841603\n","Train Epoch: 9 [23000/28539 (81%)]\tLoss: 0.656564\n","Train Epoch: 9 [24000/28539 (84%)]\tLoss: 0.863586\n","Train Epoch: 9 [25000/28539 (88%)]\tLoss: 0.769380\n","Train Epoch: 9 [26000/28539 (91%)]\tLoss: 0.805031\n","Train Epoch: 9 [27000/28539 (95%)]\tLoss: 0.644724\n","Train Epoch: 9 [28000/28539 (98%)]\tLoss: 0.721072\n","\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Test set: Average loss: 0.5577, Average CER: 0.168126 Average WER: 0.4962\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 10 [0/28539 (0%)]\tLoss: 0.650552\n","Train Epoch: 10 [1000/28539 (4%)]\tLoss: 0.704506\n","Train Epoch: 10 [2000/28539 (7%)]\tLoss: 0.765052\n","Train Epoch: 10 [3000/28539 (11%)]\tLoss: 0.700737\n","Train Epoch: 10 [4000/28539 (14%)]\tLoss: 0.772500\n","Train Epoch: 10 [5000/28539 (18%)]\tLoss: 0.657554\n","Train Epoch: 10 [6000/28539 (21%)]\tLoss: 0.588393\n","Train Epoch: 10 [7000/28539 (25%)]\tLoss: 0.725803\n","Train Epoch: 10 [8000/28539 (28%)]\tLoss: 0.568239\n","Train Epoch: 10 [9000/28539 (32%)]\tLoss: 0.780296\n","Train Epoch: 10 [10000/28539 (35%)]\tLoss: 0.752574\n","Train Epoch: 10 [11000/28539 (39%)]\tLoss: 0.716244\n","Train Epoch: 10 [12000/28539 (42%)]\tLoss: 0.717785\n","Train Epoch: 10 [13000/28539 (46%)]\tLoss: 0.672966\n","Train Epoch: 10 [14000/28539 (49%)]\tLoss: 0.604616\n","Train Epoch: 10 [15000/28539 (53%)]\tLoss: 0.990429\n","Train Epoch: 10 [16000/28539 (56%)]\tLoss: 0.644482\n","Train Epoch: 10 [17000/28539 (60%)]\tLoss: 0.760403\n","Train Epoch: 10 [18000/28539 (63%)]\tLoss: 0.693466\n","Train Epoch: 10 [19000/28539 (67%)]\tLoss: 0.540268\n","Train Epoch: 10 [20000/28539 (70%)]\tLoss: 0.567670\n","Train Epoch: 10 [21000/28539 (74%)]\tLoss: 0.567419\n","Train Epoch: 10 [22000/28539 (77%)]\tLoss: 0.644746\n","Train Epoch: 10 [23000/28539 (81%)]\tLoss: 0.718859\n","Train Epoch: 10 [24000/28539 (84%)]\tLoss: 0.674267\n","Train Epoch: 10 [25000/28539 (88%)]\tLoss: 0.742816\n","Train Epoch: 10 [26000/28539 (91%)]\tLoss: 0.744025\n","Train Epoch: 10 [27000/28539 (95%)]\tLoss: 0.580535\n","Train Epoch: 10 [28000/28539 (98%)]\tLoss: 0.658780\n","\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n","  normalized, onesided, return_complex)\n"],"name":"stderr"},{"output_type":"stream","text":["Test set: Average loss: 0.5443, Average CER: 0.162682 Average WER: 0.4822\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"92kVVEr7GR6j","executionInfo":{"status":"ok","timestamp":1606381451561,"user_tz":-330,"elapsed":2748329,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["# !7z a 'Data.7z' '/content/data/LibriSpeech/'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ucfQX3qN21az","executionInfo":{"status":"ok","timestamp":1606405426743,"user_tz":-330,"elapsed":2217,"user":{"displayName":"SACHIN SALMAN","photoUrl":"","userId":"18077240758423476746"}}},"source":["torch.save(model.to('cpu'),'ETESR.pt')"],"execution_count":10,"outputs":[]}]}